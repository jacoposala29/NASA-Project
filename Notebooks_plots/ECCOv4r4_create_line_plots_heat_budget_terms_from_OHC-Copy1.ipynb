{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce9474ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from datetime import datetime\n",
    "import numpy.matlib\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import copy\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "from functions_ecco_NEW import dayofyear_climo_extended_NEW\n",
    "\n",
    "from os.path import join,expanduser,exists,split\n",
    "user_home_dir = expanduser('~')\n",
    "sys.path.append(join(user_home_dir,'ECCOv4-py'))\n",
    "#import ecco_v4_py as ecco\n",
    "\n",
    "# Suppress warning messages for a cleaner presentation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b84542",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f014ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_var_dict_HARDDRIVE_NEEDED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d8cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f828a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region tag for title in plots\n",
    "title_tag = 'TASMAN' # NEP SWP TASMAN\n",
    "\n",
    "# Define years\n",
    "# years = np.arange(1992,2018) # 1992-2017\n",
    "\n",
    "if title_tag == 'SWP':\n",
    "    # Define box\n",
    "    lon_min = 189.5 - 360\n",
    "    lon_max = lon_min + 30\n",
    "    lat_min = -45.5\n",
    "    lat_max = lat_min + 20\n",
    "    start_time_plot = '2009-01-01'\n",
    "    end_time_plot = '2013-12-31'\n",
    "    \n",
    "elif title_tag == 'TASMAN': # (147°E, 155°E) and (45°S, 37°S)\n",
    "    # Define box\n",
    "    lon_min = 147 #- 360\n",
    "    lon_max = lon_min + 8\n",
    "    lat_min = -45\n",
    "    lat_max = lat_min + 8\n",
    "    start_time_plot = '2015-01-01'\n",
    "    end_time_plot = '2016-12-31'\n",
    "\n",
    "elif title_tag == 'NEP':\n",
    "    # Define box\n",
    "    lon_min = 209.5 - 360\n",
    "    lon_max = lon_min + 16\n",
    "    lat_min = 39.5\n",
    "    lat_max = lat_min + 11  \n",
    "    start_time_plot = '2012-01-01'\n",
    "    end_time_plot = '2016-12-31'\n",
    "\n",
    "tag_ohc_layers = '_ohc_k0_k5'\n",
    "tag_years_fname = '1992_2018'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe8d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_levels = 5 # that corresponds to 10 levels\n",
    "levels = np.arange(0,number_of_levels+1,1)\n",
    "units_tag = 'W'\n",
    "# Select maximum depth for plots\n",
    "# plot_ylim = -95 \n",
    "full_time_period = False\n",
    "\n",
    "# load_path = f'/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/metadata/'\n",
    "load_path = f'/Users/jacoposala/Downloads/'\n",
    "plot_path = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/OHC/'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec54e8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "442bac17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "ECCO_metadata = ['XC_lon', 'YC_lat', 'Z_depth', 'vol', 'area']\n",
    "\n",
    "# Create a dictionary to store the variables\n",
    "ecco_data = {}\n",
    "for ivar in ECCO_metadata:\n",
    "    file_path = f\"{load_path}/ECCOv4r4_{ivar}_1993_2017.nc\"\n",
    "    # Open the dataset and store it in the dictionary\n",
    "    ecco_data[ivar] = xr.open_dataset(file_path)\n",
    "    \n",
    "# Access the variables using the dictionary\n",
    "XC_lon = ecco_data['XC_lon']\n",
    "YC_lat = ecco_data['YC_lat']\n",
    "Z_depth = ecco_data['Z_depth'].Z_depth.sel(k=slice(None, number_of_levels))\n",
    "vol = ecco_data['vol']\n",
    "area = ecco_data['area']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8b2aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the region of interest\n",
    "lat_bounds = np.logical_and(YC_lat.YC_lat > lat_min, YC_lat.YC_lat < lat_max)\n",
    "lon_bounds = np.logical_and(XC_lon.XC_lon > lon_min, XC_lon.XC_lon < lon_max)\n",
    "lat_lon_bounds = np.logical_and(lat_bounds, lon_bounds) # if box passes the dateline, we need to add on this line \"or np.logical_and(lat_bounds2, lon_bounds2)\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c1b79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# varnames_load = ['G_total', 'G_advection', 'G_diffusion', 'G_forcing',\n",
    "#             'adv_hConv', 'adv_vConv', 'dif_hConv', 'dif_vConv',\n",
    "#             'G_advection_conv_zon', 'G_advection_conv_mer',\n",
    "#             'G_diffusion_conv_zon', 'G_diffusion_conv_mer',\n",
    "#             'DATA']\n",
    "\n",
    "varnames_load = ['G_total', 'G_advection', 'G_diffusion', 'G_forcing', 'DATA', 'adv_vConv', 'dif_vConv']\n",
    "varnames = ['G_total', 'G_advection', 'G_diffusion', 'G_forcing', 'DATA', 'adv_vConv', 'dif_vConv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15414033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "801a173b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: load\n",
      "done: box\n",
      "done: avg box\n",
      "done: append\n",
      "Saved dataset for G_total as /Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_TASMAN_avg_box/ECCOv4r4_G_total_1993_2017_avg_box_TASMAN_OHC.nc\n",
      "done: load\n",
      "done: box\n",
      "done: avg box\n",
      "done: append\n",
      "Saved dataset for G_advection as /Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_TASMAN_avg_box/ECCOv4r4_G_advection_1993_2017_avg_box_TASMAN_OHC.nc\n",
      "done: load\n",
      "done: box\n",
      "done: avg box\n",
      "done: append\n",
      "Saved dataset for G_diffusion as /Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_TASMAN_avg_box/ECCOv4r4_G_diffusion_1993_2017_avg_box_TASMAN_OHC.nc\n",
      "done: load\n",
      "done: box\n",
      "done: avg box\n",
      "done: append\n",
      "Saved dataset for G_forcing as /Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_TASMAN_avg_box/ECCOv4r4_G_forcing_1993_2017_avg_box_TASMAN_OHC.nc\n",
      "done: load\n",
      "done: box\n",
      "done: avg box\n",
      "done: append\n",
      "Saved dataset for DATA as /Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_TASMAN_avg_box/ECCOv4r4_DATA_1993_2017_avg_box_TASMAN_OHC.nc\n",
      "done: load\n",
      "done: box\n",
      "done: avg box\n",
      "done: append\n",
      "Saved dataset for adv_vConv as /Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_TASMAN_avg_box/ECCOv4r4_adv_vConv_1993_2017_avg_box_TASMAN_OHC.nc\n",
      "done: load\n",
      "done: box\n",
      "done: avg box\n",
      "done: append\n",
      "Saved dataset for dif_vConv as /Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_TASMAN_avg_box/ECCOv4r4_dif_vConv_1993_2017_avg_box_TASMAN_OHC.nc\n"
     ]
    }
   ],
   "source": [
    "if create_var_dict_HARDDRIVE_NEEDED:\n",
    "    for ivar_load, ivar in zip(varnames_load, varnames):\n",
    "        var_data = []\n",
    "        path_for_load = '/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/nc_files_zlev_or_zint'\n",
    "#         for year in years:\n",
    "#         print(year)\n",
    "\n",
    "        # Load data\n",
    "        file_path = f'{path_for_load}/ECCOv4r4_{ivar_load}{tag_ohc_layers}_1992_2018.nc'\n",
    "        dataset = xr.open_dataset(file_path)\n",
    "\n",
    "        print('done: load')\n",
    "\n",
    "        # Filter over box\n",
    "#             if year >= 2004 and (ivar_load == 'G_advection' or ivar_load == 'G_diffusion'): \n",
    "#                 ivar = ivar_load\n",
    "#                 dataset_box = dataset[ivar+'_cut'].where(lat_lon_bounds, np.nan)\n",
    "#             else:\n",
    "        dataset_box = dataset[ivar+tag_ohc_layers].where(lat_lon_bounds, np.nan)\n",
    "        area_box = area['area'].where(lat_lon_bounds, np.nan)\n",
    "        print('done: box')\n",
    "\n",
    "        # Weighted average\n",
    "        avg_box = (dataset_box * area_box).sum([\"i\", \"j\", \"tile\"]) / area_box.sum([\"i\", \"j\", \"tile\"])\n",
    "        avg_box.name = ivar_load\n",
    "        print('done: avg box')\n",
    "        var_data.append(avg_box)\n",
    "        print('done: append')\n",
    "\n",
    "        # Concatenate the datasets along the time dimension\n",
    "#         var_dataset = xr.concat(var_data, dim='time')\n",
    "        #var_dataset.name = ivar_load\n",
    "        \n",
    "        # Save the dataset as a NetCDF file\n",
    "        output_path = f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/ECCO_daily_{title_tag}_avg_box/ECCOv4r4_{ivar_load}_1993_2017_avg_box_{title_tag}_OHC.nc'\n",
    "        #output_path = \"avg_box_dsd.nc\"\n",
    "        var_data[0].to_netcdf(output_path)\n",
    "        print(f'Saved dataset for {ivar_load} as {output_path}')\n",
    "        \n",
    "        dataset.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b101ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1272c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d596dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c6767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665875c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e72263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "var_dataset = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/NEP_avg_box/ECCOv4r4_DATA_1993_2017_avg_box_NEP.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9530ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8792d257",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dataset_cumsum = copy.deepcopy(var_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b31eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab577f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ce48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdf341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import xarray as xr\n",
    "# import numpy as np\n",
    "\n",
    "# if create_var_dict_HARDDRIVE_NEEDED:\n",
    "#     # Create a dictionary to store the datasets for each variable\n",
    "#     datasets = {}\n",
    "\n",
    "#     for ivar_load, ivar in zip(varnames_load, varnames):\n",
    "#         var_data = []\n",
    "#         path_for_load = '/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/single_heat_terms'\n",
    "#         for year in years:\n",
    "#             print(year)\n",
    "#             file_path = f'{path_for_load}/{year}/ECCOv4r4_{ivar_load}_cut_{year}.nc'\n",
    "\n",
    "#             dataset = xr.open_dataset(file_path)\n",
    "            \n",
    "#             print('done: load')\n",
    "#             if year >= 2004 and ivar_load == 'G_advection': \n",
    "#                 ivar = ivar_load \n",
    "#                 dataset_box = dataset[ivar+'_cut'].where(lat_lon_bounds, np.nan)\n",
    "#             elif year >= 2004 and ivar_load == 'G_diffusion':\n",
    "#                 ivar = ivar_load\n",
    "#                 dataset_box = dataset[ivar+'_cut'].where(lat_lon_bounds, np.nan)\n",
    "#             else:\n",
    "#                 dataset_box = dataset[ivar+'_cut'].where(lat_lon_bounds, np.nan)\n",
    "#             print('done: box')\n",
    "#             # Weighted average\n",
    "#             avg_box = (dataset_box * area.area).sum([\"i\", \"j\", \"tile\"]) / area.area.sum([\"i\", \"j\", \"tile\"])\n",
    "#             avg_box.name = ivar  # Assign a name to the DataArray\n",
    "#             print('done: avg box')\n",
    "#             var_data.append(avg_box)\n",
    "#             print('done: append')\n",
    "\n",
    "#         # Concatenate the datasets along the time dimension\n",
    "#         var_dataset = xr.concat(var_data, dim='time')\n",
    "\n",
    "#         # Create a Dataset from the concatenated DataArray\n",
    "#         var_dataset = var_dataset.to_dataset(name=ivar)\n",
    "\n",
    "#         # Rename the variable in the dataset\n",
    "#         var_dataset = var_dataset.rename({ivar: f'ECCOv4r4_{ivar_load}_1993_2017_avg_box_{title_tag}'})\n",
    "\n",
    "#         # Store the variable dataset in the dictionary\n",
    "#         datasets[ivar_load] = var_dataset\n",
    "\n",
    "#         # Save the dataset as a NetCDF file\n",
    "#         output_path = f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/{title_tag}_avg_box/ECCOv4r4_{ivar_load}_1993_2017_avg_box_{title_tag}.nc'  # Replace with your desired output path\n",
    "#         var_dataset.to_netcdf(output_path)\n",
    "#         print(f'Saved dataset for {ivar_load} as {output_path}')\n",
    "#         ciao\n",
    "#         dataset.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32528e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store sliced data in the dictionary\n",
    "# test1 = G_advection_global.G_advection_conv_cut.where(lat_lon_bounds, np.nan)\n",
    "# avg = (test1* area.area).sum([\"i\", \"j\", \"tile\"]) / area.area.sum([\"i\", \"j\", \"tile\"])\n",
    "# avg.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weighted average terms\n",
    "output_path = f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/{title_tag}_avg_box/'\n",
    "\n",
    "# Rename variables in other xarray datasets\n",
    "G_total_1992_2017_k0_k9_box_wgtd_avg = xr.open_dataset(output_path + f'G_total_avg_box_{title_tag}_dataset.nc').rename({'__xarray_dataarray_variable__': 'G_total_1992_2017_k0_k9_box_wgtd_avg'})\n",
    "G_total_1992_2017_k0_k9_box_wgtd_avg = G_total_1992_2017_k0_k9_box_wgtd_avg.G_total_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "G_advection_conv_1992_2017_k0_k9_box_wgtd_avg = xr.open_dataset(output_path + f'G_advection_avg_box_{title_tag}_dataset.nc').rename({'__xarray_dataarray_variable__': 'G_advection_conv_1992_2017_k0_k9_box_wgtd_avg'})\n",
    "G_advection_conv_1992_2017_k0_k9_box_wgtd_avg = G_advection_conv_1992_2017_k0_k9_box_wgtd_avg.G_advection_conv_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg = xr.open_dataset(output_path + f'G_diffusion_avg_box_{title_tag}_dataset.nc').rename({'__xarray_dataarray_variable__': 'G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg'})\n",
    "G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg = G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg.G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "G_forcing_1992_2017_k0_k9_box_wgtd_avg = xr.open_dataset(output_path + f'G_forcing_avg_box_{title_tag}_dataset.nc').rename({'__xarray_dataarray_variable__': 'G_forcing_1992_2017_k0_k9_box_wgtd_avg'})\n",
    "G_forcing_1992_2017_k0_k9_box_wgtd_avg = G_forcing_1992_2017_k0_k9_box_wgtd_avg.G_forcing_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "DATA_1992_2017_k0_k9_box_wgtd_avg = xr.open_dataset(output_path + f'DATA_avg_box_{title_tag}_dataset.nc').rename({'__xarray_dataarray_variable__': 'DATA_1992_2017_k0_k9_box_wgtd_avg'})\n",
    "DATA_1992_2017_k0_k9_box_wgtd_avg = DATA_1992_2017_k0_k9_box_wgtd_avg.DATA_1992_2017_k0_k9_box_wgtd_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0891eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df698d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['G_total_1992_2017_k0_k9_box_wgtd_avg', \n",
    "           'G_advection_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    "           'G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    "           'G_forcing_1992_2017_k0_k9_box_wgtd_avg',\n",
    "           'DATA_1992_2017_k0_k9_box_wgtd_avg']\n",
    "varname_list = ['G_total',\n",
    "               'G_advection',\n",
    "               'G_diffusion',\n",
    "               'G_forcing',\n",
    "               'DATA']\n",
    "\n",
    "title_list = ['NEP', 'SWP', 'TASMAN']\n",
    "\n",
    "if title_tag == 'SWP':\n",
    "    # Define box\n",
    "    lon_min = 189.5 - 360\n",
    "    lon_max = lon_min + 30\n",
    "    lat_min = -45.5\n",
    "    lat_max = lat_min + 20\n",
    "    start_time_plot = '2009-01-01'\n",
    "    end_time_plot = '2013-12-31'\n",
    "    \n",
    "elif title_tag == 'TASMAN': # (147°E, 155°E) and (45°S, 37°S)\n",
    "    # Define box\n",
    "    lon_min = 147 #- 360\n",
    "    lon_max = lon_min + 8\n",
    "    lat_min = -45\n",
    "    lat_max = lat_min + 8\n",
    "    start_time_plot = '2015-01-01'\n",
    "    end_time_plot = '2016-12-31'\n",
    "\n",
    "elif title_tag == 'NEP':\n",
    "    # Define box\n",
    "    lon_min = 209.5 - 360\n",
    "    lon_max = lon_min + 16\n",
    "    lat_min = 39.5\n",
    "    lat_max = lat_min + 11  \n",
    "    start_time_plot = '2012-01-01'\n",
    "    end_time_plot = '2016-12-31'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598d511f",
   "metadata": {},
   "source": [
    "# Create input files for MHW Matlab code to make it run with a single file for each term with all the regions included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a00fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold datasets for each variable\n",
    "combined_datasets = {}\n",
    "\n",
    "for ivar, ivarname in zip(var_list, varname_list):\n",
    "    combined_list = []\n",
    "\n",
    "    for i, ititle in enumerate(title_list):\n",
    "        output_path = f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/{title_tag}_avg_box/'\n",
    "        # Load and rename data\n",
    "        data = xr.open_dataset(output_path + f'{ivarname}_avg_box_{title_tag}_dataset.nc').rename({'__xarray_dataarray_variable__': f'{ivarname}_1992_2017_k0_k9_box_wgtd_avg'})\n",
    "        data = eval(f'data.{ivarname}_1992_2017_k0_k9_box_wgtd_avg')\n",
    "        \n",
    "        if ititle == 'SWP':\n",
    "            # Define box\n",
    "            lon_min = 189.5 - 360\n",
    "            lon_max = lon_min + 30\n",
    "            lat_min = -45.5\n",
    "            lat_max = lat_min + 20\n",
    "\n",
    "        elif ititle == 'TASMAN':\n",
    "            # Define box\n",
    "            lon_min = 147\n",
    "            lon_max = lon_min + 8\n",
    "            lat_min = -45\n",
    "            lat_max = lat_min + 8\n",
    "\n",
    "        elif ititle == 'NEP':\n",
    "            # Define box\n",
    "            lon_min = 209.5 - 360\n",
    "            lon_max = lon_min + 16\n",
    "            lat_min = 39.5\n",
    "            lat_max = lat_min + 11\n",
    "\n",
    "        time = data.time.values\n",
    "        k = data.k.values\n",
    "\n",
    "        # Compute the center latitude and longitude values\n",
    "        lon_center_of_box = (lon_min + lon_max) / 2\n",
    "        lat_center_of_box = (lat_min + lat_max) / 2\n",
    "\n",
    "        # Create index_of_center_box array\n",
    "        index_of_box = np.array([i])  # Single box\n",
    "\n",
    "        # Expand dimensions of the data to match the new shape\n",
    "        data_expanded = np.expand_dims(data, axis=1)  # Add a new dimension for index_of_center_box\n",
    "\n",
    "        # Create the xarray DataArray\n",
    "        da = xr.DataArray(\n",
    "            data_expanded,\n",
    "            coords={\n",
    "                \"time\": time,\n",
    "                \"index_of_box\": index_of_box,\n",
    "                \"k\": k\n",
    "            },\n",
    "            dims=[\"time\", \"index_of_box\", \"k\"]\n",
    "        )\n",
    "\n",
    "        # Convert DataArray to Dataset\n",
    "        ds = da.to_dataset(name=ivar)\n",
    "\n",
    "        # Add useful info as variables\n",
    "        ds = ds.assign(\n",
    "            title_tag=(\"index_of_box\", [ititle]),\n",
    "            lat_center_of_box=(\"index_of_box\", [lat_center_of_box]),\n",
    "            lon_center_of_box=(\"index_of_box\", [lon_center_of_box]),\n",
    "            lon_min=(\"index_of_box\", [lon_min]),\n",
    "            lon_max=(\"index_of_box\", [lon_max]),\n",
    "            lat_min=(\"index_of_box\", [lat_min]),\n",
    "            lat_max=(\"index_of_box\", [lat_max])\n",
    "        )\n",
    "\n",
    "        combined_list.append(ds)\n",
    "\n",
    "    # Combine datasets for all regions for this variable\n",
    "    combined_datasets[ivar] = xr.concat(combined_list, dim='index_of_box')\n",
    "\n",
    "# Save the combined datasets\n",
    "for ivar, ds in combined_datasets.items():\n",
    "    save_path = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/Matlab_inputs/'\n",
    "    ds.to_netcdf(save_path + f'Matlab_Inputs_combined_regions_{ivar}_dataset.nc')\n",
    "\n",
    "# Example of accessing a combined dataset\n",
    "# print(combined_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c6015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_center_of_box and lon_center_of_box variables with coordinate index_of_box\n",
    "# add variable name G_total_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "# add title_tag with coordinate index_of_box\n",
    "# add lon_min = 209.5 - 360\n",
    "# lon_max = lon_min + 16\n",
    "# lat_min = 39.5\n",
    "# lat_max = lat_min + 11\n",
    "# as variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a83bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f801f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in DATA_1992_2017_k0_k9_box_wgtd_avg.time.values:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_plot = ['G_total_1992_2017_k0_k9_box_wgtd_avg', \\\n",
    "                 'G_advection_conv_1992_2017_k0_k9_box_wgtd_avg', \\\n",
    "                 'G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg', \\\n",
    "                 'G_forcing_1992_2017_k0_k9_box_wgtd_avg']\n",
    "\n",
    "# Total convergence of advection and diffusion (horizontal and vertical)\n",
    "Conv_total_box_wgt_area_avg = G_advection_conv_1992_2017_k0_k9_box_wgtd_avg + G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "# Sum of terms in RHS of equation\n",
    "rhs_box_wgt_area_avg = Conv_total_box_wgt_area_avg + G_forcing_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "# Residuals calculated within the box\n",
    "res_2_all_box_wgt_area_avg = rhs_box_wgt_area_avg - G_total_1992_2017_k0_k9_box_wgtd_avg\n",
    "\n",
    "# varnames_plot.append('res_2_all_box_wgt_area_avg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b66103",
   "metadata": {},
   "source": [
    "## Plot anomalies for DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "varname_data = ['DATA_1992_2017_k0_k9_box_wgtd_avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k_value in range(1):\n",
    "    # Create a new figure for each layer\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    label = 'DATA'\n",
    "    for varname in varname_data:\n",
    "        climo = eval(varname).groupby('time.dayofyear').mean('time')\n",
    "        anom_data = eval(varname).groupby('time.dayofyear') - climo\n",
    "        cut_data_anom = anom_data.sel(time=slice(start_time_plot, end_time_plot))\n",
    "\n",
    "        layer_data_anom = cut_data_anom.sel(k=k_value)\n",
    "        plt.plot(layer_data_anom['time'], layer_data_anom, label=label, linewidth=2.5)\n",
    "\n",
    "#     plt.ylim(-1E-5, 1E-5)\n",
    "    plt.title(f'Anomaly Plot - Layer k={k_value}, {title_tag} region', fontsize = 16)\n",
    "    plt.xlabel('Time', fontsize = 16)\n",
    "    plt.ylabel('Anomaly Value', fontsize = 16)\n",
    "    plt.axhline(y=0, color='k')\n",
    "    plt.legend()\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.legend(fontsize = 12)\n",
    "    \n",
    "#     # Save or show the figure\n",
    "#     plt.savefig(plot_path + f'DATA_anomalies_lineplot_layer_k{k_value}_{title_tag}_region.png', dpi=1000)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18b86c",
   "metadata": {},
   "source": [
    "## Plot anomalies for each k level - all terms on one plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbb0c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# varnames_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29a4c37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k_value in range(10):\n",
    "#     # Create a new figure for each layer\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "#     labels = ['G_total', 'G_advection', 'G_diffusion', 'G_forcing', 'Residuals']\n",
    "#     i = 0\n",
    "#     for varname in varnames_plot:\n",
    "#         climo = eval(varname).groupby('time.dayofyear').mean('time')\n",
    "#         anom_data = eval(varname).groupby('time.dayofyear') - climo\n",
    "#         cut_data_anom = anom_data.sel(time=slice(start_time_plot, end_time_plot))\n",
    "#         layer_data_anom = cut_data_anom.sel(k=k_value)\n",
    "#         plt.plot(layer_data_anom['time'], layer_data_anom, label=labels[i])\n",
    "#         i = i+1\n",
    "\n",
    "# #     plt.ylim(-1E-5, 1E-5)\n",
    "#     plt.title(f'Anomaly Plot - Layer k={k_value}, {title_tag} region', fontsize = 16)\n",
    "#     plt.xlabel('Time', fontsize = 16)\n",
    "#     plt.ylabel('Anomaly Value', fontsize = 16)\n",
    "#     plt.legend()\n",
    "#     plt.xticks(fontsize = 14)\n",
    "#     plt.yticks(fontsize = 14)\n",
    "#     plt.legend(fontsize = 12)\n",
    "    \n",
    "#     # Save or show the figure\n",
    "#     plt.savefig(plot_path + f'anomalies_lineplot_layer_k{k_value}_{title_tag}_region.png', dpi=1000)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898cae0b",
   "metadata": {},
   "source": [
    "## Plot the cumulative sum of the anomalies for each term for each k level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c8327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k_value in range(10):\n",
    "#     # Create a new figure for each layer\n",
    "#     plt.figure(figsize=(15, 6))\n",
    "#     labels = ['G_total', 'G_advection', 'G_diffusion', 'G_forcing', 'Residuals']\n",
    "#     i = 0\n",
    "#     for varname in varnames_plot:\n",
    "#         climo = eval(varname).groupby('time.month').mean('time')\n",
    "#         anom_data = eval(varname).groupby('time.month') - climo\n",
    "#         cut_data_anom = anom_data.sel(time=slice(start_time_plot, end_time_plot))\n",
    "\n",
    "#         layer_data_anom = cut_data_anom.sel(k=k_value)\n",
    "#         cumulative_sum = layer_data_anom.cumsum(dim='time')\n",
    "#         plt.plot(layer_data_anom['time'], cumulative_sum, label=labels[i], linewidth=2.5)\n",
    "#         i = i+1\n",
    "        \n",
    "#     plt.title(f'Cumulative Sum Plot - Layer k={k_value}, {title_tag} region', fontsize = 16)\n",
    "#     plt.xlabel('Time', fontsize = 16)\n",
    "#     plt.ylabel('Cumulative Sum', fontsize = 16)\n",
    "#     plt.legend()\n",
    "#     plt.xticks(fontsize = 14)\n",
    "#     plt.yticks(fontsize = 14)\n",
    "#     plt.legend(fontsize = 12)\n",
    "    \n",
    "#     # Save or show the figure\n",
    "#     plt.savefig(plot_path + f'cumulative_sum_lineplot_layer_k{k_value}_{title_tag}_region.png', dpi=1000)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbf02c",
   "metadata": {},
   "source": [
    "## Calculate cumulative sum between k_min and k_max \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4bd455",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_min = 0\n",
    "k_max = 5 # 5 max 9\n",
    "\n",
    "thickness = np.abs(np.diff(Z_depth))\n",
    "thickness = np.abs(np.diff(Z_depth))[k_min:k_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa517eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_plot = ['G_total_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_advection_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_forcing_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'DATA_1992_2017_k0_k9_box_wgtd_avg']\n",
    "\n",
    "varnames_plot = ['G_total_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_advection_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_forcing_1992_2017_k0_k9_box_wgtd_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ab758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_2save_mat = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/mat_files'\n",
    "for ivar in varnames_plot:\n",
    "    data_all = {}\n",
    "    data = copy.deepcopy(eval(ivar))\n",
    "    data_all['data_dayofyear'] = data.time.dt.dayofyear.values\n",
    "    data_all['data_month'] = data.time.dt.month.values\n",
    "    data_all['data_year'] = data.time.dt.year.values\n",
    "    data_all['data_day'] = data.time.dt.day.values\n",
    "    data_all['data'] = data.values\n",
    "    savemat(f\"{path_2save_mat}/{ivar}_{title_tag}.mat\", data_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672476f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce71a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import pchip_interpolate\n",
    "# var_names = ['G_total_1992_2017_k0_k9_box_wgtd_avg',\n",
    "#  'G_advection_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    "#  'G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    "#  'G_forcing_1992_2017_k0_k9_box_wgtd_avg',\n",
    "#  'DATA_1992_2017_k0_k9_box_wgtd_avg']\n",
    "var_names = ['G_total_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_advection_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg',\n",
    " 'G_forcing_1992_2017_k0_k9_box_wgtd_avg',\n",
    "            'DATA_1992_2017_k0_k9_box_wgtd_avg']\n",
    "\n",
    "# var_names = ['DATA_1992_2017_k0_k9_box_wgtd_avg']\n",
    "# Loop over variables\n",
    "for var_name in var_names:\n",
    "    # Load data\n",
    "    bfr = scipy.io.loadmat(path_2save_mat + '/' + var_name + '_' + title_tag + '.mat')\n",
    "    data = bfr['data']\n",
    "\n",
    "    # Initialize array for climatology\n",
    "    bfr_data_climo = np.empty_like(data) * np.nan\n",
    "    \n",
    "    # Loop over each day of the year\n",
    "    for i in range(len(bfr['data_dayofyear'][0])):\n",
    "\n",
    "        # Create a mask for the specific day and month\n",
    "        msk = np.logical_and(bfr['data_month'] == bfr['data_month'][0][i], bfr['data_day'] == bfr['data_day'][0][i])\n",
    "\n",
    "        # Repeat msk 10 times along the second axis\n",
    "        msk_repeated = np.broadcast_to(msk.T, data.shape)\n",
    "        # Apply the repeated mask to each column of the data array\n",
    "        masked_data = data[msk_repeated].reshape(-1, data.shape[1])\n",
    "\n",
    "        # Calculate climatological average for the specific day and assign to the mask\n",
    "        bfr_data_climo[np.where(msk_repeated)] = np.tile(np.nanmean(masked_data, axis=0), (np.sum(msk), 1)).ravel()\n",
    "    \n",
    "    # mask for Feb 29 - we average previous day (Feb 28) and following day (Mar 1)\n",
    "    msk_feb29 = np.logical_and(bfr['data_month'][0] == 2, bfr['data_day'][0] == 29)\n",
    "\n",
    "    index = np.where(msk_feb29)[0]\n",
    "\n",
    "    for i_ind in np.arange(0,len(index)):\n",
    "        bfr_data_climo[index[i_ind],:] = (bfr_data_climo[index[i_ind]-1,:] + bfr_data_climo[index[i_ind]+1,:])/2\n",
    "#         bfr_data_climo[index[i_ind],:] = bfr_data_climo[index[i_ind]-1,:]\n",
    "    \n",
    "        \n",
    "    # interpolation for Feb 29, Feb 28 and Mar 1 (between Feb 27 and Mar 2)\n",
    "#     else:\n",
    "#         for iday, imonth in zip([28,29,1], [2,2,3]):\n",
    "#             msk_feb28_feb29_mar1 = np.logical_and(bfr['data_month'][0] == imonth, bfr['data_day'][0] == iday)\n",
    "#             bfr_data_climo[msk_feb28_feb29_mar1,:] = np.nan\n",
    "    \n",
    "#         for ilev in np.arange(0, np.shape(bfr_data_climo)[1]):\n",
    "#             msk = np.isfinite(bfr_data_climo[:, ilev])\n",
    "#             xint = np.arange(0, np.shape(bfr_data_climo)[0])\n",
    "#             bfr_data_climo[:,ilev] = scipy.interpolate.pchip_interpolate(xint[msk], \\\n",
    "#                                                bfr_data_climo[msk, ilev], xint)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Prepare output dictionary\n",
    "    bfr_4_output = {\n",
    "        'data': data,\n",
    "        'data_dayofyear': bfr['data_dayofyear'],\n",
    "        'data_month': bfr['data_month'],\n",
    "        'data_year': bfr['data_year'],\n",
    "        'data_day': bfr['data_day'],\n",
    "        'data_climo': bfr_data_climo\n",
    "    }\n",
    "\n",
    "    # Use variable name as key in the output dictionary\n",
    "    globals()[var_name] = bfr_4_output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e6425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c27990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk_test = np.logical_and(bfr['data_month'][0] == 2, bfr['data_day'][0] == 28)\n",
    "# for k in np.arange(0,5,1):\n",
    "#     print(np.unique(bfr_data_climo[msk_test,k]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk_test = np.logical_and(bfr['data_month'][0] == 2, bfr['data_day'][0] == 29)\n",
    "# for k in np.arange(0,5,1):\n",
    "#     print(np.unique(bfr_data_climo[msk_test,k]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f76822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# msk_test = np.logical_and(bfr['data_month'][0] == 3, bfr['data_day'][0] == 1)\n",
    "# for k in np.arange(0,5,1):\n",
    "#     print(np.unique(bfr_data_climo[msk_test,k]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e865d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa389119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for ivar in var_names:\n",
    "    \n",
    "#     d2plot = globals()[ivar]\n",
    "    \n",
    "#     plt.figure(figsize=(15,6))\n",
    "#     plt.plot(d2plot['data_climo'])\n",
    "#     plt.title(ivar)\n",
    "#     plt.xlim(1,366)  # Set x-axis limits\n",
    "#     plt.axvline(x=58, linestyle = '--', linewidth=.5)\n",
    "#     plt.xlim(56,60)\n",
    "#     plt.ylim(.023, .025)\n",
    "\n",
    "# #     plt.colorbar()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d051e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,6))\n",
    "# plt.pcolor(np.abs(G_total_1992_2017_k0_k9_box_wgtd_avg['data'] -\n",
    "#            G_advection_conv_1992_2017_k0_k9_box_wgtd_avg['data'] -\n",
    "#            G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg['data'] -\n",
    "#            G_forcing_1992_2017_k0_k9_box_wgtd_avg['data']), vmin = 0, vmax = 2.5E-14)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5197296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,6))\n",
    "# plt.pcolor(np.abs(G_total_1992_2017_k0_k9_box_wgtd_avg['data_climo'] -\n",
    "#            G_advection_conv_1992_2017_k0_k9_box_wgtd_avg['data_climo'] -\n",
    "#            G_diffusion_conv_1992_2017_k0_k9_box_wgtd_avg['data_climo'] -\n",
    "#            G_forcing_1992_2017_k0_k9_box_wgtd_avg['data_climo']), vmin = 0, vmax = 2.5E-14)\n",
    "# plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9526a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_global_condition_MHWall = np.load('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/bfr_data_avg_area_tot_NEP_MHWall.np.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_area_global = np.load('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/bfr_data_avg_area_tot_NEP_MHWall.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32655ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ce125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb47b54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a2012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots between kmin and kmax (OHC)\n",
    "\n",
    "ind = 0\n",
    "start_time = datetime.strptime(start_time_plot, '%Y-%m-%d').toordinal()\n",
    "end_time = datetime.strptime(end_time_plot, '%Y-%m-%d').toordinal()\n",
    "\n",
    "# cols = plt.cm.jet(np.linspace(0, 1, len(var_names)))\n",
    "cols = ['aqua', 'darkorange', 'limegreen', 'red', 'black']\n",
    "\n",
    "labels = []\n",
    "for ivar in varnames_plot:\n",
    "    if 'G_total' in ivar:\n",
    "        labels.append('Total Tendency')\n",
    "    if 'G_forcing' in ivar:\n",
    "        labels.append('Forcing')\n",
    "    if 'G_adv' in ivar:\n",
    "        labels.append('Advective Convergence')\n",
    "    if 'G_diff' in ivar:\n",
    "        labels.append('Diffusive Convergence')\n",
    "    if 'DATA' in ivar:\n",
    "        labels.append('ΔT')\n",
    "        \n",
    "plt.figure(figsize=(15,6))      \n",
    "for ivar in range(len(varnames_plot)):\n",
    "    print(varnames_plot[ivar])\n",
    "    d2plot = eval(varnames_plot[ivar])\n",
    "\n",
    "    d2plot_dnum = [datetime(*d).toordinal() for d in zip(d2plot['data_year'][0], d2plot['data_month'][0], d2plot['data_day'][0])]\n",
    "    d2plot_msk = (np.array(d2plot_dnum) >= start_time) & (np.array(d2plot_dnum) <= end_time)\n",
    "    \n",
    "    d2plot_val = d2plot['data'] - d2plot['data_climo']\n",
    "    d2plot_val_sel = d2plot_val[d2plot_msk]\n",
    "    \n",
    "    \n",
    "    d2plot_val_sel = ((d2plot_val_sel[:, k_min+1:k_max+1] + d2plot_val_sel[:, k_min:k_max])\n",
    "                        * thickness).sum(axis=1) / 2\n",
    "    \n",
    "    \n",
    "    ordinal_dates = np.array(d2plot_dnum)[d2plot_msk]\n",
    "    \n",
    "    datetime_time = [datetime.fromordinal(date) for date in ordinal_dates]\n",
    "\n",
    "    \n",
    "    if 'DATA' in var_names[ivar]:\n",
    "        plt.plot(datetime_time, d2plot_val_sel - d2plot_val_sel[0], color=cols[ivar], label='ΔT', linewidth=1.5, linestyle='--')\n",
    "    else:\n",
    "        plt.plot(datetime_time, np.cumsum(d2plot_val_sel) * 24 * 3600, color=cols[ivar], label=labels[ivar], linewidth=2, linestyle='-')\n",
    "\n",
    "# Add residuals to plot\n",
    "plt.plot(datetime_time, res_2_all_box_wgt_area_avg.sel(time=slice(start_time_plot, end_time_plot))[:,ind], color='fuchsia', label='Residual', linewidth=2, linestyle='-')\n",
    "\n",
    "plt.title(f'Temperature change since t=0 averaged between layer k={k_min} and k={k_max} - {title_tag} region', fontsize = 16)\n",
    "plt.xlabel('Time', fontsize = 16)\n",
    "plt.ylabel('ΔT, degC', fontsize = 16)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "# plt.ylim(-2,+1)\n",
    "# plt.ylim(-.3,.3)\n",
    "plt.ylim(-1,1)\n",
    "plt.axhline (y = 0, color = 'k', linestyle = '--', alpha = 0.5, linewidth = 1.5)\n",
    "plt.legend(fontsize=14)\n",
    "# plt.savefig(plot_path + f'temperature_change_lineplot_layer_k{k_min}_k{k_max}_{title_tag}_region.png', dpi=1000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6c4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30fca4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make plots for each layer \n",
    "\n",
    "k_lev = [0,1,2,3,4,5]\n",
    "\n",
    "# start_time_plot = '1992-01-02'\n",
    "# end_time_plot = '1992-12-31'\n",
    "\n",
    "start_time = datetime.strptime(start_time_plot, '%Y-%m-%d').toordinal()\n",
    "end_time = datetime.strptime(end_time_plot, '%Y-%m-%d').toordinal()\n",
    "\n",
    "# cols = plt.cm.jet(np.linspace(0, 1, len(var_names)))\n",
    "cols = ['aqua', 'darkorange', 'limegreen', 'red', 'black']\n",
    "\n",
    "labels = []\n",
    "for ivar in varnames_plot:\n",
    "    if 'G_total' in ivar:\n",
    "        labels.append('Total Tendency')\n",
    "    if 'G_forcing' in ivar:\n",
    "        labels.append('Forcing')\n",
    "    if 'G_adv' in ivar:\n",
    "        labels.append('Advective Convergence')\n",
    "    if 'G_diff' in ivar:\n",
    "        labels.append('Diffusive Convergence')\n",
    "    if 'DATA' in ivar:\n",
    "        labels.append('ΔT')\n",
    "        \n",
    "for i_k in k_lev:\n",
    "    plt.figure(figsize=(15,6))      \n",
    "    for ivar in range(len(varnames_plot)):\n",
    "        print(varnames_plot[ivar])\n",
    "        d2plot = eval(varnames_plot[ivar])\n",
    "\n",
    "        d2plot_dnum = [datetime(*d).toordinal() for d in zip(d2plot['data_year'][0], d2plot['data_month'][0], d2plot['data_day'][0])]\n",
    "        d2plot_msk = (np.array(d2plot_dnum) >= start_time) & (np.array(d2plot_dnum) <= end_time)\n",
    "\n",
    "        d2plot_val = d2plot['data'][:,i_k] - d2plot['data_climo'][:,i_k]\n",
    "        d2plot_val_sel = d2plot_val[d2plot_msk]\n",
    "\n",
    "\n",
    "        ordinal_dates = np.array(d2plot_dnum)[d2plot_msk]\n",
    "\n",
    "        datetime_time = [datetime.fromordinal(date) for date in ordinal_dates]\n",
    "\n",
    "\n",
    "        if 'DATA' in var_names[ivar]:\n",
    "            plt.plot(datetime_time, d2plot_val_sel - d2plot_val_sel[0], color=cols[ivar], label='ΔT', linewidth=1.5, linestyle='--')\n",
    "        else:\n",
    "            plt.plot(datetime_time, np.cumsum(d2plot_val_sel) * 24 * 3600, color=cols[ivar], label=labels[ivar], linewidth=2, linestyle='-')\n",
    "\n",
    "    # Add residuals to plot\n",
    "    plt.plot(datetime_time, res_2_all_box_wgt_area_avg.sel(time=slice(start_time_plot, end_time_plot))[:,ind], color='fuchsia', label='Residual', linewidth=2, linestyle='-')\n",
    "\n",
    "    plt.title(f'Temperature change since t=0 averaged for layer k={i_k} - {title_tag} region', fontsize = 16)\n",
    "    plt.xlabel('Time', fontsize = 16)\n",
    "    plt.ylabel('ΔT, degC', fontsize = 16)\n",
    "    plt.xticks(fontsize = 14)\n",
    "    plt.yticks(fontsize = 14)\n",
    "    plt.axhline (y = 0, color = 'k', linestyle = '--', alpha = 0.5, linewidth = 1.5)\n",
    "    plt.legend(fontsize=14)\n",
    "#     plt.xlim(datetime(2012, 2, 1), datetime(2012, 4, 30))  # Set x-axis limits\n",
    "\n",
    "#     plt.savefig(plot_path + f'temperature_change_lineplot_layer_k{i_k}_{title_tag}_region.png', dpi=1000)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2plot_val_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bfca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcfb54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea7aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_1992_2017_k0_k9_box_wgtd_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d8c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DATA_1992_2017_k0_k9_box_wgtd_avg.time[8500:9000], DATA_1992_2017_k0_k9_box_wgtd_avg[8500:9000,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6003d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fab32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd2a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f74e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dayofyear_climo_extended_NEW(varname_input, var_input):\n",
    "#     data_input = copy.deepcopy(var_input).to_dataset()\n",
    "#     data_input = data_input - data_input.mean(dim='time')\n",
    "#     print(data_input)\n",
    "    \n",
    "    \n",
    "#     bfr_climo_extended_year_array = data_input.time.dt.year.values\n",
    "    \n",
    "#     bfr_climo_extended_dayofyear_array = data_input.time.dt.dayofyear.values\n",
    "    \n",
    "#     data_input_values = data_input[varname_input].values\n",
    "    \n",
    "# #     print(type(bfr_climo_extended_values))\n",
    "# #     print(np.shape(bfr_climo_extended_values))\n",
    "# #     print(bfr_climo_extended_values)\n",
    "#     output_climo_extended_values = copy.deepcopy(data_input_values)\n",
    "    \n",
    "#     for i in np.arange(0, np.shape(output_climo_extended_values)[0]):\n",
    "#         mask_climo = bfr_climo_extended_dayofyear_array == bfr_climo_extended_dayofyear_array[i]\n",
    "#         output_climo_extended_values[mask_climo,:] = np.mean(data_input_values[mask_climo,:])\n",
    "    \n",
    "# #     plt.plot(output_climo_extended_values[0:365,0])\n",
    "# #     plt.plot(data_input_values[0:365,0])\n",
    "    \n",
    "#     output_climo_extended = copy.deepcopy(data_input)\n",
    "#     output_climo_extended[varname_input] = (('time', 'k'), output_climo_extended_values)\n",
    "#     output_climo_extended = output_climo_extended + data_input.mean(dim='time')\n",
    "    \n",
    "#     return(output_climo_extended[varname_input])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640834dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define variables to plot\n",
    "\n",
    "thickness = np.abs(np.diff(Z_depth))\n",
    "thickness = np.abs(np.diff(Z_depth))[k_min:k_max]\n",
    "\n",
    "vars2plot = []\n",
    "vars2plot_diff = []\n",
    "\n",
    "for varname in varnames_plot:\n",
    "    print(varname)\n",
    "    climo = eval(varname).groupby('time.dayofyear').mean('time') # shape (366, 10): days & levels\n",
    "    climo_NEW = dayofyear_climo_extended_NEW(varname_input=varname, var_input=eval(varname))\n",
    "    anom_data = eval(varname) - climo_NEW #dayofyear_climo_extended(varname_input = varname, var_input=eval(varname), climo=climo)\n",
    "    anom_data = climo_NEW #dayofyear_climo_extended(varname_input = varname, var_input=eval(varname), climo=climo)\n",
    "#     anom_data = eval(varname).groupby('time.dayofyear') - climo\n",
    "    cut_data_anom = anom_data.sel(time=slice(start_time_plot, end_time_plot))\n",
    "\n",
    "    # TRAPEZOIDAL RULE\n",
    "    variable_integral = ((cut_data_anom[:, k_min+1:k_max+1].values + cut_data_anom[:, k_min:k_max].values)\n",
    "                        * thickness).sum(axis=1) / 2\n",
    "\n",
    "    \n",
    "    if 'DATA' in varname:\n",
    "        var2save = (variable_integral - variable_integral[0])/np.abs(np.sum(thickness))\n",
    "    else:\n",
    "        cumulative_sum = np.cumsum(variable_integral)\n",
    "        var2save = cumulative_sum*24*60*60/np.abs(np.sum(thickness))\n",
    "        \n",
    "    vars2plot.append(var2save)\n",
    "    \n",
    "#     vars2plot_diff.append(var2save-vars2plot[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183452aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting cumulative sums for each term on one single plot\n",
    "# plt.figure(figsize=(15, 6))\n",
    "\n",
    "# labels = []\n",
    "# for ivar in varnames_plot:\n",
    "#     if 'G_total' in ivar:\n",
    "#         labels.append('Total Tendency')\n",
    "#     if 'G_forcing' in ivar:\n",
    "#         labels.append('Forcing')\n",
    "#     if 'G_adv' in ivar:\n",
    "#         labels.append('Advective Convergence')\n",
    "#     if 'G_diff' in ivar:\n",
    "#         labels.append('Diffusive Convergence')\n",
    "#     if 'res' in ivar:\n",
    "#         labels.append('Residual')\n",
    "#     if 'DATA' in ivar:\n",
    "#         labels.append('ΔT')\n",
    "\n",
    "# colors = ['red', 'green', 'blue', 'magenta', 'black', 'grey']\n",
    "# lstlye = ['-', '-', '-', '-', '-', '-']\n",
    "# i = 0\n",
    "# for varname, ivars2plot in zip(varnames_plot, vars2plot):\n",
    "#     plt.plot(cut_data_anom.time, ivars2plot, label=labels[i], linewidth=1.5, color=colors[i], linestyle=lstlye[i])\n",
    "#     i = i+1\n",
    "# plt.axhline (y = 0, color = 'k', linestyle = '--', alpha = 0.5)\n",
    "# # if varname\n",
    "# plt.title(f'Temperature change since t=0 averaged between layer k={k_min} and k={k_max} - {title_tag} region', fontsize = 16)\n",
    "# plt.xlabel('Time', fontsize = 16)\n",
    "# plt.ylabel('ΔT, degC', fontsize = 16)\n",
    "# plt.xticks(fontsize = 14)\n",
    "# plt.yticks(fontsize = 14)\n",
    "# plt.legend(fontsize = 12)\n",
    "# # plt.ylim(-.0001, .0001)\n",
    "# # plt.savefig(plot_path + f'cumulative_sum_integral_lineplot_layer_k{k_min}_k{k_max}_{title_tag}_region.png', dpi=1000)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72996f68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Plotting cumulative sums for each term on one single plot\n",
    "# plt.figure(figsize=(15, 6))\n",
    "\n",
    "# labels = []\n",
    "# for ivar in varnames_plot:\n",
    "#     if 'G_total' in ivar:\n",
    "#         labels.append('Total Tendency')\n",
    "#     if 'G_forcing' in ivar:\n",
    "#         labels.append('Forcing')\n",
    "#     if 'G_adv' in ivar:\n",
    "#         labels.append('Advective Convergence')\n",
    "#     if 'G_diff' in ivar:\n",
    "#         labels.append('Diffusive Convergence')\n",
    "#     if 'res' in ivar:\n",
    "#         labels.append('Residual')\n",
    "#     if 'DATA' in ivar:\n",
    "#         labels.append('ΔT')\n",
    "\n",
    "# colors = ['red', 'green', 'blue', 'magenta', 'black', 'grey']\n",
    "# lstlye = ['-', '-', '-', '-', '-', '-']\n",
    "# i = 0\n",
    "# for varname, ivars2plot in zip(varnames_plot, vars2plot):\n",
    "#     plt.plot(cut_data_anom.time, ivars2plot, label=labels[i], linewidth=1.5, color=colors[i], linestyle=lstlye[i])\n",
    "#     i = i+1\n",
    "# plt.axhline (y = 0, color = 'k', linestyle = '--', alpha = 0.5)\n",
    "# # if varname\n",
    "# plt.title(f'Temperature change since t=0 averaged between layer k={k_min} and k={k_max} - {title_tag} region', fontsize = 16)\n",
    "# plt.xlabel('Time', fontsize = 16)\n",
    "# plt.ylabel('ΔT, degC', fontsize = 16)\n",
    "# plt.xticks(fontsize = 14)\n",
    "# plt.yticks(fontsize = 14)\n",
    "# plt.legend(fontsize = 12)\n",
    "# # plt.ylim(-.0001, .0001)\n",
    "# # plt.savefig(plot_path + f'cumulative_sum_integral_lineplot_layer_k{k_min}_k{k_max}_{title_tag}_region.png', dpi=1000)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a5677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dayofyear_climo_extended(varname_input, var_input, climo):\n",
    "#     bfr_climo_extended = copy.deepcopy(var_input).to_dataset()\n",
    "#     bfr_climo = climo.values\n",
    "\n",
    "# #     bfr_climo_extended_year = [pd.DatetimeIndex([x]).year for x in bfr_climo_extended.coords['time'].time.values]\n",
    "# #     bfr_climo_extended_year_array = np.vstack([x.values.flatten() for x in bfr_climo_extended_year]).flatten()\n",
    "# #     bfr_climo_extended_dayofyear = [pd.DatetimeIndex([x]).dayofyear for x in bfr_climo_extended.coords['time'].time.values]\n",
    "# #     bfr_climo_extended_dayofyear_array = np.vstack([x.values.flatten() for x in bfr_climo_extended_dayofyear]).flatten()\n",
    "#     bfr_climo_extended_year_array = bfr_climo_extended.time.dt.year.values\n",
    "#     bfr_climo_extended_dayofyear_array = bfr_climo_extended.time.dt.dayofyear.values\n",
    "#     print(type(bfr_climo_extended_dayofyear_array))\n",
    "#     print(np.shape(bfr_climo_extended_dayofyear_array))\n",
    "#     print(bfr_climo_extended_dayofyear_array)\n",
    "#     ciao\n",
    "#     n = len(np.unique(bfr_climo_extended_year))\n",
    "\n",
    "#     bfr_climo_extended_var = bfr_climo_extended[varname_input].values*np.nan\n",
    "\n",
    "#     for iii, iday in enumerate(np.arange(1,np.shape(bfr_climo)[0]+1)):\n",
    "#         for ilev in np.arange(0,np.shape(bfr_climo_extended_var)[1]):\n",
    "# #             mask_idx = np.where(bfr_climo_extended_dayofyear_array == iday)\n",
    "#             mask_idx = []\n",
    "#             mask_idx_year = []\n",
    "#             for i, j in enumerate(bfr_climo_extended_dayofyear_array):\n",
    "#                 if j == iday:\n",
    "#                     mask_idx.append(i)\n",
    "#                     mask_idx_year.append(bfr_climo_extended_year_array[i])\n",
    "\n",
    "            \n",
    "#             for iidx, idx in enumerate(mask_idx):\n",
    "\n",
    "#                 if pd.Timestamp(bfr_climo_extended_year_array[iidx],12,31).dayofyear == 366: # leap year\n",
    "\n",
    "#                     bfr_climo_extended_var[idx, ilev] = bfr_climo[iii, ilev]\n",
    "                    \n",
    "#                 else: # not-leap year\n",
    "                    \n",
    "#                     if idx <= 59:\n",
    "#                         bfr_climo_extended_var[idx, ilev] = bfr_climo[iii, ilev]\n",
    "#                     else:\n",
    "#                         bfr_climo_extended_var[idx, ilev] = bfr_climo[iii+1, ilev]\n",
    "                        \n",
    "\n",
    "# #             bfr_climo_extended_var[mask_idx, ilev] = bfr_climo[iii, ilev]\n",
    "            \n",
    "#     bfr_climo_extended[varname_input] = ((\"time\",\"k\"), bfr_climo_extended_var)\n",
    "#     return(bfr_climo_extended[varname_input])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dayofyear_climo_extended_NEW(varname_input, var_input):\n",
    "#     data_input = copy.deepcopy(var_input).to_dataset()\n",
    "\n",
    "#     bfr_climo_extended_year_array = data_input.time.dt.year.values\n",
    "#     bfr_climo_extended_dayofyear_array = data_input.time.dt.dayofyear.values\n",
    "#     data_input_values = data_input[varname_input].values\n",
    "    \n",
    "# #     print(type(bfr_climo_extended_values))\n",
    "# #     print(np.shape(bfr_climo_extended_values))\n",
    "# #     print(bfr_climo_extended_values)\n",
    "#     output_climo_extended_values = copy.deepcopy(data_input_values)\n",
    "    \n",
    "#     for i in np.arange(0, np.shape(output_climo_extended_values)[0]):\n",
    "#         mask_climo = bfr_climo_extended_dayofyear_array == bfr_climo_extended_dayofyear_array[i]\n",
    "#         output_climo_extended_values[mask_climo,:] = np.mean(data_input_values[mask_climo,:])\n",
    "    \n",
    "# #     plt.plot(output_climo_extended_values[0:365,0])\n",
    "# #     plt.plot(data_input_values[0:365,0])\n",
    "    \n",
    "#     output_climo_extended = copy.deepcopy(data_input)\n",
    "#     output_climo_extended[varname_input] = (('time', 'k'), output_climo_extended_values)\n",
    "    \n",
    "#     return(output_climo_extended[varname_input])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9db424",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd073a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321c063",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa2b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA (degC) -> DATA_anom -> weighted avg -> DATA_wgt_avg (degC) -> integral k0-k5 -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import NaturalEarthFeature\n",
    "\n",
    "# Define the coordinates for the three regions and their labels\n",
    "regions = [\n",
    "    {\"lon_min\": 189.5 - 360, \"lon_max\": 189.5 - 360 + 30, \"lat_min\": -45.5, \"lat_max\": -45.5 + 20, \"label\": \"1\"},\n",
    "    {\"lon_min\": 147, \"lon_max\": 147 + 8, \"lat_min\": -45, \"lat_max\": -45 + 8, \"label\": \"2\"},\n",
    "    {\"lon_min\": 209.5 - 360, \"lon_max\": 209.5 - 360 + 16, \"lat_min\": 39.5, \"lat_max\": 39.5 + 11, \"label\": \"3\"}\n",
    "]\n",
    "\n",
    "# Create a map\n",
    "fig = plt.figure(figsize=(20, 8))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=180))\n",
    "\n",
    "# Add continents and coastlines\n",
    "ax.coastlines(resolution='10m', linewidth=0.5)\n",
    "ax.stock_img()\n",
    "\n",
    "# Plot the boxes\n",
    "for region in regions:\n",
    "    ax.plot([region[\"lon_min\"], region[\"lon_max\"], region[\"lon_max\"], region[\"lon_min\"], region[\"lon_min\"]],\n",
    "            [region[\"lat_min\"], region[\"lat_min\"], region[\"lat_max\"], region[\"lat_max\"], region[\"lat_min\"]],\n",
    "            color='red', transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add labels to the regions\n",
    "    ax.text((region[\"lon_min\"] + region[\"lon_max\"]) / 2, (region[\"lat_min\"] + region[\"lat_max\"]) / 2, region[\"label\"],\n",
    "            horizontalalignment='center', verticalalignment='center', transform=ccrs.PlateCarree(), fontsize = 15)\n",
    "\n",
    "# Set extent and gridlines centered at 180 longitude (Pacific Ocean in the middle)\n",
    "ax.set_extent([-80, 80, -90, 90], crs=ccrs.PlateCarree(central_longitude=180))\n",
    "\n",
    "# Add title and show plot\n",
    "# plt.title('Three Boxes with Red Lines and Background Continents and Sea')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1388e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f00a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8eb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbbb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bafe16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd2072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6c2740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcf7be47",
   "metadata": {},
   "source": [
    "## Plot a map of the SST anomaly (Dec 2015-Feb 2016) to reproduce Oliver et al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308c4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecco_v4_py as ecco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad6147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_2plot_map_k0 = DATA_tile8_1992_2017_k0_k9[:,0,:,:]\n",
    "# climo = DATA_2plot_map_k0.sel(time=slice('1992-01-01', '2005-12-31')).groupby('time.dayofyear').mean('time')\n",
    "# anom_data = DATA_2plot_map_k0.groupby('time.dayofyear') - climo\n",
    "# cut_data_anom = anom_data.sel(time=slice('2015-12-01', '2016-02-29'))\n",
    "# anom_data.to_netcdf('SST_anom_TASMAN.nc4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db1fe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SST_anom_TASMAN = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/outputs/SST_anom_TASMAN.nc4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21162435",
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_anom_TASMAN_cut = SST_anom_TASMAN.sel(time=slice('2015-12-01', '2016-02-29'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ba7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_SST_anom_TASMAN_cut = SST_anom_TASMAN_cut.DATA_tile8.mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82126b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# Assuming your DataArray is named 'your_data_array'\n",
    "data_array = mean_SST_anom_TASMAN_cut\n",
    "XC_lon['XC_lon'] = xr.where(XC_lon['XC_lon'] < 0, XC_lon['XC_lon'] + 360, XC_lon['XC_lon'])\n",
    "\n",
    "# Set up the plot\n",
    "fig = plt.figure(figsize=(10,8), dpi= 90)\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Set up levels and a centered norm\n",
    "levels = np.linspace(-5, 5, 21)\n",
    "cmap = 'bwr'\n",
    "norm = BoundaryNorm(levels, ncolors=256)\n",
    "\n",
    "# Set up levels and a centered norm\n",
    "levels = [-3.5, -2.5, -2, -1.5, -1, 1, 1.5, 2, 2.5, 3.5]\n",
    "cmap = 'bwr'\n",
    "norm = TwoSlopeNorm(vmin=-5, vcenter=0, vmax=5)\n",
    "\n",
    "\n",
    "# Plot using contourf\n",
    "contour_plot = plt.contourf(XC_lon.XC_lon, YC_lat.YC_lat, data_array, \n",
    "                            cmap=cmap, levels=levels, norm=norm, \n",
    "                            transform=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "\n",
    "plt.xlim([143,180])\n",
    "plt.ylim([-55,-5])\n",
    "\n",
    "# Add colorbar with white in the center\n",
    "cbar = plt.colorbar(contour_plot, extend='both')\n",
    "cbar.set_label('Temperature Anomaly (deg C)', fontsize = 14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163be4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee880925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c56c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cce73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbefd98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf420a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58998945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54806c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb09307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162b170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb10df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45fd63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d198154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb6ba96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adea587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b84e5f71",
   "metadata": {},
   "source": [
    "## Plot depth vs time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9212a5bc",
   "metadata": {},
   "source": [
    "### Define time range to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_time_period: \n",
    "    #Define time for plotting - FULL TIME SERIES\n",
    "    plot_xlim_min = datetime.strptime(\"Jan 1 1993 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "    plot_xlim_year_month_min = '1993_01'\n",
    "    plot_xlim_max = datetime.strptime(\"Dec 31 2016 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "    plot_xlim_year_month_max = '2016_12'    \n",
    "else: \n",
    "    if title_tag == 'NEP':\n",
    "        # Define time for plotting - BLOB REGION\n",
    "        plot_xlim_min = datetime.strptime(\"Jan 1 2012 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "        plot_xlim_year_month_min = '2012_01'\n",
    "        plot_xlim_max = datetime.strptime(\"Dec 31 2016 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "        plot_xlim_year_month_max = '2016_12'\n",
    "    elif title_tag == 'SWP':\n",
    "        # Define time for plotting - SW PACIFIC REGION\n",
    "        plot_xlim_min = datetime.strptime(\"Jan 1 2009 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "        plot_xlim_year_month_min = '2009_01'\n",
    "        plot_xlim_max = datetime.strptime(\"Dec 31 2013 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "        plot_xlim_year_month_max = '2013_12'    \n",
    "#         plot_xlim_min = datetime.strptime(\"Jan 1 2005 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "#         plot_xlim_year_month_min = '2005_01'\n",
    "#         plot_xlim_max = datetime.strptime(\"Dec 31 2016 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "#         plot_xlim_year_month_max = '2016_12' \n",
    "    elif title_tag == 'TASMAN':\n",
    "        # Define time for plotting - SW PACIFIC REGION\n",
    "        plot_xlim_min = datetime.strptime(\"Sep 1 2015 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "        plot_xlim_year_month_min = '2015_09'\n",
    "        plot_xlim_max = datetime.strptime(\"Aug 31 2016 01:00AM\", '%b %d %Y %I:%M%p')\n",
    "        plot_xlim_year_month_max = '2016_08'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20983e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MidpointNormalize(mcolors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        super(MidpointNormalize, self).__init__(vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y), np.isnan(value))\n",
    "    \n",
    "def ecco_plot_time_vs_depth_JS_auto_limits(ivar, ivar_tag, ivar_box_tag):\n",
    "    # Remove seasonal cycle\n",
    "    if ivar in ['DATA']:\n",
    "        bfr = eval(ivar).transpose()\n",
    "    else:\n",
    "        bfr = eval(ivar + ivar_box_tag).transpose()\n",
    "    climo=bfr.groupby('time.month').mean('time')\n",
    "    bfr_anom=bfr.groupby('time.month')-climo\n",
    "    bfr_2plot = eval('bfr'+ivar_tag)\n",
    "#     if flag_density:\n",
    "#         bfr_rho_cont = eval('RHOAnoma' + ivar_box_tag)# + ivar_tag) # density should be calculated just using the total\n",
    "    fig = plt.figure(figsize=(15,6))\n",
    "    \n",
    "    clim_calc = max(np.abs(np.quantile(bfr_2plot,0)),np.abs(np.quantile(bfr_2plot,1)))\n",
    "    mylevs = np.linspace(-clim_calc, + clim_calc, 61)\n",
    "    norm = MidpointNormalize(midpoint=0)\n",
    "    \n",
    "    \n",
    "    clim = 3e-6\n",
    "    mylevs = np.linspace(-clim, clim, 31)\n",
    "    \n",
    "    \n",
    "#     max_abs_var = max(max(bfr_2plot))\n",
    "#     mylevs = np.linspace(-max_abs_var, max_abs_var, 31)\n",
    "    # Plot variables\n",
    "#     plt.contourf(bfr_anom.time, Z_depth, bfr_2plot, cmap=plt.cm.bwr)#, levels=mylevs, vmin=min(mylevs), vmax=max(mylevs), extend = 'both')\n",
    "    plt.contourf(bfr_anom.time, Z_depth, bfr_2plot.values, cmap=plt.cm.bwr, levels=mylevs, norm=norm, vmin=min(mylevs), vmax=max(mylevs), extend = 'both')\n",
    "#     print(Z_depth)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "    # Plot rho countours with or without seasonal anomalies\n",
    "#     if flag_density:\n",
    "#         plt.contour(bfr_rho_cont.time, Z_depth, bfr_rho_cont.transpose()+1029, colors='k', levels=np.arange(1020,1028,.5), linewidths = 0.5)\n",
    "    if ivar in ['ConvH_total_horiz']:\n",
    "        plt.title(ivar.split('_tile8')[0] + ivar_tag +' (degC m3/s)' + ', ' + title_tag, fontsize = 14)\n",
    "    else:\n",
    "        plt.title(ivar.split('_tile8')[0] + ivar_tag + ' (' + units_tag + '), ' + title_tag, fontsize = 14)\n",
    "    plt.ylim(plot_ylim,0) \n",
    "    plt.xlabel('Year', fontsize = 12)\n",
    "    plt.xlim(plot_xlim_min, plot_xlim_max)\n",
    "    plt.ylabel('Depth, m', fontsize = 12)\n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12)\n",
    "    plt.show()\n",
    "    fig.tight_layout() \n",
    "#     if ivar_tag =='':\n",
    "#         fig.savefig('./depth_vs_time_plots' + '/total/' + 'depth_vs_time_' \\\n",
    "#                     + ivar + '_' + title_tag + '_' + plot_xlim_year_month_min \\\n",
    "#                     + '_' + plot_xlim_year_month_max + ivar_tag + '.jpg', dpi = 900, bbox_inches='tight')\n",
    "#     else:\n",
    "#         fig.savefig('./depth_vs_time_plots' + '/anom/' + 'depth_vs_time_' \\\n",
    "#                     + ivar + '_' + title_tag + '_' + plot_xlim_year_month_min \\\n",
    "#                     + '_' + plot_xlim_year_month_max + ivar_tag + '.jpg', dpi = 900, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a10f3",
   "metadata": {},
   "source": [
    "### Actual plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames_plot = ['G_total_tile8_1992_2017_k0_k9_box', 'G_advection_conv_tile8_1992_2017_k0_k9_box', \\\n",
    "                 'G_diffusion_conv_tile8_1992_2017_k0_k9_box', 'G_forcing_tile8_1992_2017_k0_k9_box']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9d5df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ivar_box_tag = '_wgtd_avg_' + title_tag\n",
    "\n",
    "for ivar_tag in ['', '_anom']:\n",
    "    for ivar in varnames_plot:\n",
    "        # Avoid plots of non-relevant terms\n",
    "        if (ivar not in ['time', 'XC_lon','YC_lat','Z_depth','vol','area']):\n",
    "            ecco_plot_time_vs_depth_JS_auto_limits(ivar, ivar_tag, ivar_box_tag)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9885d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3b1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23223fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecco_plot_time_vs_depth_JS_cumulative_sum(ivar, ivar_tag, ivar_box_tag):\n",
    "    # Remove seasonal cycle\n",
    "    if ivar in ['DATA']:\n",
    "        bfr = eval(ivar).transpose()\n",
    "    else:\n",
    "        bfr = eval(ivar + ivar_box_tag).transpose()\n",
    "    climo = bfr.groupby('time.month').mean('time')\n",
    "    bfr_anom = bfr.groupby('time.month') - climo\n",
    "\n",
    "    # Calculate cumulative sum in time\n",
    "    bfr_anom_cumul = bfr_anom.cumsum(axis=0)  # Sum along the time axis\n",
    "\n",
    "    bfr_2plot = eval('bfr' + ivar_tag)\n",
    "\n",
    "    # Plot variables\n",
    "    fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Adjust clim_calc and mylevs based on cumulative sum behavior\n",
    "#     clim_calc = max(abs(np.min(bfr_anom_cumul)), abs(np.max(bfr_anom_cumul)))\n",
    "#     mylevs = np.linspace(-clim_calc, +clim_calc, 61)\n",
    "    clim_calc = max(np.abs(np.quantile(bfr_2plot,0)),np.abs(np.quantile(bfr_2plot,1)))\n",
    "    mylevs = np.linspace(-clim_calc, + clim_calc, 61)\n",
    "    norm = MidpointNormalize(midpoint=0)\n",
    "    \n",
    "    \n",
    "    clim = 5e-6\n",
    "    mylevs = np.linspace(-clim, clim, 31)\n",
    "    \n",
    "    norm = MidpointNormalize(midpoint=0)\n",
    "\n",
    "    plt.contourf(bfr_anom_cumul.time, Z_depth, bfr_anom_cumul.values,\n",
    "                cmap=plt.cm.bwr, levels=mylevs, norm=norm,\n",
    "                vmin=min(mylevs), vmax=max(mylevs), extend='both')\n",
    "\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "    # Adjust title based on cumulative sum\n",
    "    if ivar in ['ConvH_total_horiz']:\n",
    "        plt.title(ivar.split('_tile8')[0] + ivar_tag + ' (cumulative degC m3/s)' + ', ' + title_tag, fontsize=14)\n",
    "    else:\n",
    "        plt.title(ivar.split('_tile8')[0] + ivar_tag + ' (cumulative ' + units_tag + '), ' + title_tag, fontsize=14)\n",
    "\n",
    "    plt.ylim(plot_ylim, 0)\n",
    "    plt.xlabel('Year', fontsize=12)\n",
    "    plt.xlim(plot_xlim_min, plot_xlim_max)\n",
    "    plt.ylabel('Depth, m', fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9de5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ivar_box_tag = '_wgtd_avg_' + title_tag\n",
    "\n",
    "for ivar_tag in ['', '_anom']:\n",
    "    for ivar in varnames_plot:\n",
    "        # Avoid plots of non-relevant terms\n",
    "        if (ivar not in ['time', 'XC_lon','YC_lat','Z_depth','vol','area']):\n",
    "            ecco_plot_time_vs_depth_JS_cumulative_sum(ivar, ivar_tag, ivar_box_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ac531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
