{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d98581a",
   "metadata": {},
   "source": [
    "### ECCOv4r4 DAILY - create a single file for each term with all the years, then select a region, horizontal average, save a .nc file and create time vs depth plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedc8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import sys\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "## Import the ecco_v4_py library into Python\n",
    "## =========================================\n",
    "##    If ecco_v4_py is not installed in your local Python library, \n",
    "##    tell Python where to find it.  The example below adds\n",
    "##    ecco_v4_py to the user's path if it is stored in the folder\n",
    "##    ECCOv4-py under the user's home directory\n",
    "\n",
    "from os.path import join,expanduser,exists,split\n",
    "user_home_dir = expanduser('~')\n",
    "sys.path.append(join(user_home_dir,'ECCOv4-py'))\n",
    "import ecco_v4_py as ecco\n",
    "\n",
    "# Suppress warning messages for a cleaner presentation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bd321e",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2973d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "ECCO_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/'\n",
    "save_dir = join(ECCO_dir,'outputs/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f613ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = 2004  # Define the start year\n",
    "year_end = 2018  # Define the end year (NOT included, will stop the year before this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabc042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define limits of the box \n",
    "# SWP \n",
    "lon_min = 189.5 - 360\n",
    "lon_max = lon_min + 30\n",
    "lat_min = -45.5\n",
    "lat_max = lat_min + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bddd801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model grid\n",
    "grid_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/eccov4r4_grid/'\n",
    "ecco_grid = ecco.load_ecco_grid_nc(grid_dir,'GRID_GEOMETRY_ECCO_V4r4_native_llc0090.nc')\n",
    "\n",
    "# Define XC and YC\n",
    "YC_lat = ecco_grid.YC\n",
    "XC_lon = ecco_grid.XC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fcb0f7",
   "metadata": {},
   "source": [
    "### Select a single level and save a single file for every terms (for all the years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da41e365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "G_advection_conv_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "G_diffusion_conv_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "G_forcing_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "adv_hConv_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "adv_vConv_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "dif_hConv_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "dif_vConv_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "G_advection_conv_zon_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "G_advection_conv_mer_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "G_diffusion_conv_zon_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "G_diffusion_conv_mer_tile8_box saved\n",
      "Done year: 2004\n",
      "Done year: 2005\n",
      "Done year: 2006\n",
      "Done year: 2007\n",
      "Done year: 2008\n",
      "Done year: 2009\n",
      "Done year: 2010\n",
      "Done year: 2011\n",
      "Done year: 2012\n",
      "Done year: 2013\n",
      "Done year: 2014\n",
      "Done year: 2015\n",
      "Done year: 2016\n",
      "Done year: 2017\n",
      "DATA_tile8_box saved\n"
     ]
    }
   ],
   "source": [
    "# Mask creation\n",
    "lat_bounds = np.logical_and(YC_lat > lat_min, YC_lat < lat_max)\n",
    "lon_bounds = np.logical_and(XC_lon > lon_min, XC_lon < lon_max)\n",
    "lat_lon_bounds = np.logical_and(lat_bounds, lon_bounds)\n",
    "\n",
    "# Define the variables to be saved\n",
    "varnames = ['G_total_tile8', 'G_advection_conv_tile8', 'G_diffusion_conv_tile8', 'G_forcing_tile8',\n",
    "            'adv_hConv_tile8', 'adv_vConv_tile8', 'dif_hConv_tile8', 'dif_vConv_tile8',\n",
    "            'G_advection_conv_zon_tile8', 'G_advection_conv_mer_tile8',\n",
    "            'G_diffusion_conv_zon_tile8', 'G_diffusion_conv_mer_tile8',\n",
    "            'DATA_tile8']\n",
    "\n",
    "# Loop through the variables\n",
    "for varname in varnames:\n",
    "    final_dataset = None  # Initialize final dataset for each variable\n",
    "\n",
    "    # Loop through the years from 2004 to 2018\n",
    "    for year in range(year_start, year_end):\n",
    "        # Define the folder name for the current year\n",
    "        folder_year = str(year)\n",
    "\n",
    "        # Create the directory path for loading\n",
    "        load_path = os.path.join(save_dir, 'tile8_single_heat_terms', folder_year)\n",
    "\n",
    "        # Define the file name for loading\n",
    "        load_file_name = f'ECCOv4r4_{varname}_{year}.nc'\n",
    "\n",
    "        # Load the NetCDF file from the specified directory\n",
    "        load_file_path = os.path.join(load_path, load_file_name)\n",
    "        dataset = xr.open_dataset(load_file_path)\n",
    "\n",
    "        # Apply the mask to the dataset\n",
    "        var_box = dataset[varname].where(lat_lon_bounds, np.nan)\n",
    "\n",
    "        # Remove NaN values manually\n",
    "        var_box = var_box.dropna(dim='i', how='all')\n",
    "        var_box = var_box.dropna(dim='j', how='all')\n",
    "        \n",
    "        # Select the data for tile 8\n",
    "        var_box_tile8 = var_box.sel(tile=8)\n",
    "        \n",
    "        # Ensure coordinates match the final dataset\n",
    "        if final_dataset is None:\n",
    "            final_dataset = var_box_tile8\n",
    "        else:\n",
    "            # Concatenate along the 'time' dimension\n",
    "            final_dataset = xr.concat([final_dataset, var_box_tile8], dim='time')\n",
    "        print('Done year: ' + str(year))\n",
    "\n",
    "    # Save the final dataset for the current variable\n",
    "    final_dataset.to_netcdf(save_dir + '/nc_files_for_a_region/' + f'ECCOv4r4_{varname}_box_{lon_min}_{lon_max}_{lat_min}_{lat_max}_{year_start}_{year_end}.nc', format='NETCDF4')\n",
    "    print(f'{varname}_box saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b19029d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c6bded",
   "metadata": {},
   "source": [
    "### Test plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a94d15f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.pcolor(final_dataset[1,1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0db327c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# var2plot = final_dataset[1, 1, :, :]\n",
    "\n",
    "\n",
    "# import matplotlib.patches as patches\n",
    "\n",
    "# def draw_box(box_lims, ax):\n",
    "#     # box_lims = [lat_max, lat_min, lon_max, lon_min]\n",
    "#     ax.add_patch(patches.Rectangle((box_lims[3], box_lims[1]), box_lims[2] - box_lims[3], box_lims[0] - box_lims[1],\\\n",
    "#                        fill=False,\n",
    "#                        color=\"red\",\n",
    "#                        linewidth=1,\n",
    "#                        linestyle='--'))\n",
    "\n",
    "# # Create a new map\n",
    "# fig = plt.figure(figsize=(10, 6))\n",
    "# ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "# # Set the extent to cover the entire globe\n",
    "# ax.set_global()\n",
    "\n",
    "# # Add land and ocean features\n",
    "# ax.add_feature(cfeature.LAND)\n",
    "# ax.add_feature(cfeature.OCEAN)\n",
    "\n",
    "# # Draw coastlines and gridlines\n",
    "# ax.coastlines()\n",
    "# ax.gridlines(draw_labels=True)\n",
    "\n",
    "# # Define the box limits\n",
    "# box_lims = [lat_max, lat_min, lon_max, lon_min]\n",
    "\n",
    "# # Draw the box\n",
    "# draw_box(box_lims, ax)\n",
    "\n",
    "# # Assuming G_total_tile8_box[1,1,:,:,8] is a 2D array\n",
    "# # Replace this with the actual data and appropriate coordinates\n",
    "# XC = var2plot.XC\n",
    "# YC = var2plot.YC\n",
    "# # XC, YC = np.meshgrid(XC, YC)  # Assuming XC and YC are provided as arrays\n",
    "# data = var2plot\n",
    "\n",
    "# # Add the data to the plot\n",
    "# im = ax.pcolormesh(XC, YC, data, shading='auto', transform=ccrs.PlateCarree())\n",
    "\n",
    "# # Add a colorbar\n",
    "# cbar = fig.colorbar(im, ax=ax, orientation='vertical', pad=0.05)\n",
    "# cbar.set_label('G_total_tile8_box[1,1,:,:,:]')\n",
    "\n",
    "# plt.title('Map of the Globe with Land and Sea, Box, and Data')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1104fda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b809a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba39fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac714dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c026aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac86f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527b46ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d23c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336ee83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6968dc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9453fda2",
   "metadata": {},
   "source": [
    "### Compute the integral for X levels and save a single file for every terms (for all the years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The deepest ocean bottom is set to 6145m below the surface, with the vertical grid spacing increasing \n",
    "# from 10m near the surface to 457m near the ocean bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23209bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if do_integral_tag:\n",
    "    z_flag = 'zint'\n",
    "    Z_depth = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/\\\n",
    "data/outputs/single_heat_terms/ECCOv4r4_Z_depth_1993_2017.nc').Z_depth\n",
    "\n",
    "    expected_order = ('time', 'tile', 'k', 'j', 'i')\n",
    "\n",
    "    varnames = ['G_total_cut', 'G_advection_cut', 'G_diffusion_cut', 'G_forcing_cut',\n",
    "                'adv_hConv_cut', 'adv_vConv_cut', 'dif_hConv_cut', 'dif_vConv_cut',\n",
    "                'G_advection_conv_zon_cut', 'G_advection_conv_mer_cut',\n",
    "                'G_diffusion_conv_zon_cut', 'G_diffusion_conv_mer_cut', \n",
    "                'DATA_cut']\n",
    "    \n",
    "    for varname in varnames:\n",
    "        print('Processing ', varname)\n",
    "        print('Year being processed:')\n",
    "        final_dataset = None  # Initialize final dataset for each variable\n",
    "\n",
    "        for year in range(year_start, year_end):\n",
    "            print(year)\n",
    "            folder_year = str(year)\n",
    "            load_path = os.path.join(integral_dir, 'single_heat_terms', folder_year)\n",
    "            load_file_name = f'ECCOv4r4_{varname}_{year}.nc'\n",
    "            load_file_path = os.path.join(load_path, load_file_name)\n",
    "            dataset = xr.open_dataset(load_file_path)\n",
    "\n",
    "            # Fix the order of coordinates for G_forcing_cut, adv_vConv_cut, and dif_vConv_cut\n",
    "            if varname in ['G_forcing_cut', 'adv_vConv_cut', 'dif_vConv_cut']:\n",
    "                dataset = dataset.transpose('time', 'k', 'tile', 'j', 'i')\n",
    "            \n",
    "            if varname == 'DATA_cut':\n",
    "                # Conversion to Kelvin for DATA_cut\n",
    "                variable_cut = dataset[varname] + 273.15\n",
    "            else:\n",
    "                variable_cut = dataset[varname]\n",
    "                        \n",
    "            depth_index_top_integral = 0  # corresponds to 5m\n",
    "            depth_index_bottom_integral = 5  # corresponds to 55m\n",
    "\n",
    "            thickness = np.abs(np.diff(Z_depth))\n",
    "\n",
    "            selected_variable_cut = variable_cut[:, depth_index_top_integral:depth_index_bottom_integral, :, :, :]\n",
    "            selected_thickness = thickness[depth_index_top_integral:depth_index_bottom_integral - 1]\n",
    "            reshaped_thickness_diff = np.reshape(selected_thickness, (1, -1, 1, 1, 1))\n",
    "\n",
    "            variable_integral = (\n",
    "                (selected_variable_cut[:, :-1, :, :, :].values + selected_variable_cut[:, 1:, :, :, :].values)\n",
    "                * reshaped_thickness_diff\n",
    "            ).sum(axis=1) / 2\n",
    "\n",
    "            # Save the integral to a new NetCDF file\n",
    "            save_path = os.path.join(save_dir + '/nc_files_zlev_or_zint/')\n",
    "            save_file_name = f'integral_{varname}_{year}.nc'\n",
    "            save_file_path = os.path.join(save_path, save_file_name)\n",
    "            \n",
    "            # Modify variable name and add _ohc_k0k5\n",
    "            varname_modified = varname.replace('_cut', '') + f'_ohc_k{depth_index_top_integral}_k{depth_index_bottom_integral}'\n",
    "        \n",
    "            integral_dataset = xr.Dataset(\n",
    "                {\n",
    "                    varname_modified: ([\"time\", \"tile\", \"j\", \"i\"], variable_integral)\n",
    "                },\n",
    "                coords={\n",
    "                    \"time\": variable_cut.time.values,\n",
    "                    \"tile\": np.arange(13),  # Adjust the range according to the number of tiles\n",
    "                    \"j\": np.arange(90),  # Adjust the range according to the latitude dimensions\n",
    "                    \"i\": np.arange(90),  # Adjust the range according to the longitude dimensions\n",
    "                }\n",
    "            )\n",
    "            # Save files for single years\n",
    "            #integral_dataset.to_netcdf(save_file_path)\n",
    "\n",
    "            if final_dataset is None:\n",
    "                final_dataset = integral_dataset\n",
    "            else:\n",
    "                final_dataset = xr.concat([final_dataset, integral_dataset], dim='time')\n",
    "\n",
    "        # At the end of all years, save the concatenated file, too\n",
    "        if final_dataset is not None:\n",
    "            # Save the final dataset to a single NetCDF file\n",
    "            final_save_path = os.path.join(save_path, f'ECCOv4r4_{varname_modified}_{year_start}_{year_end}.nc')\n",
    "            \n",
    "            final_dataset.to_netcdf(final_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75836edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbe86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01846cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing = xr.open_dataset('/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/single_heat_terms/2006/ECCOv4r4_G_forcing_cut_2006.nc')\n",
    "forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875f66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = xr.open_dataset('/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/single_heat_terms/2004/ECCOv4r4_DATA_cut_2004.nc')\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b328864",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/outputs/nc_files_zlev_or_zint/ECCOv4r4_G_diffusion_conv_mer_cut_zlev9_2004_2018.nc')\n",
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a260d684",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab58f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d14e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
