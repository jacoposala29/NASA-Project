{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537e9983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import scipy.io\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import cartopy.crs as ccrs\n",
    "from matplotlib.colors import LogNorm\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.colors as colors\n",
    "from datetime import date, timedelta, datetime\n",
    "import pandas\n",
    "import copy\n",
    "\n",
    "\n",
    "from os.path import join,expanduser,exists,split\n",
    "user_home_dir = expanduser('~')\n",
    "sys.path.append(join(user_home_dir,'ECCOv4-py'))\n",
    "import ecco_v4_py as ecco\n",
    "\n",
    "# Suppress warning messages for a cleaner presentation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789a9df",
   "metadata": {},
   "source": [
    "### What we have so far (February 2024):\n",
    "### OISST MONTHLY only (keep in mind that the name of the plots has daily in it - needs to be fixed in the future):\n",
    "    - 1993-2016 and 2004-2016\n",
    "##### How to run it:\n",
    "    - lev_or_int = 'oisst'\n",
    "    - dataset_tag = 'oisst_v2'\n",
    "    - daily_monthly_plot_tag = 'daily'\n",
    "    - ecco_monthly_tag_field = 'heat'\n",
    "    - ecco_monthly_tag = False \n",
    "    - ecco_daily_tag = True \n",
    "    - test_peaks_tag = False\n",
    "    - delta_time_tag = '1tstep'\n",
    "    \n",
    "### ECCO MONTHLY - HEAT:\n",
    "    - 1993-2016 and 2004-2016\n",
    "##### How to run it:\n",
    "    - lev_or_int = 'zlev01'\n",
    "    - dataset_tag = 'ECCOv4r4_heat'\n",
    "    - daily_monthly_plot_tag = 'monthly'\n",
    "    - ecco_monthly_tag_field = 'heat'\n",
    "    - ecco_monthly_tag = True \n",
    "    - ecco_daily_tag = False  \n",
    "    - test_peaks_tag = False\n",
    "    - delta_time_tag = '1tstep'\n",
    "    \n",
    "### ECCO monthly OHC: \n",
    "    - 1993-2016 and 2004-2016:\n",
    "##### How to run it:\n",
    "    - lev_or_int = zlev01\n",
    "    - dataset_tag = 'ECCOv4r4_heat'\n",
    "    - ecco_monthly_tag_field = 'ohc_to50m'\n",
    "    - daily_monthly_plot_tag = monthly\n",
    "    - ecco_monthly_tag = True\n",
    "    - ecco_daily_tag = False\n",
    "    - delta_time_tag = '1tstep'   \n",
    "\n",
    "### ECCO daily: \n",
    "    - 1992-2018 and 2004-2016:\n",
    "    \n",
    "##### How to run it:\n",
    "    - lev_or_int = zlev00 or zlev05 or zlev09\n",
    "    - dataset_tag = 'ECCOv4r4_heat'\n",
    "    - ecco_monthly_tag_field = 'heat'\n",
    "    - daily_monthly_plot_tag = daily\n",
    "    - ecco_monthly_tag = False\n",
    "    - ecco_daily_tag = True\n",
    "    - delta_time_tag = '5tstep' \n",
    "    \n",
    "### Argo: \n",
    "    - 2004-2016:\n",
    "    \n",
    "##### How to run it:\n",
    "    - lev_or_int = argo\n",
    "    - dataset_tag = 'argo_ohc15_50'\n",
    "    - ecco_monthly_tag_field = 'heat'\n",
    "    - daily_monthly_plot_tag = daily\n",
    "    - ecco_monthly_tag = False\n",
    "    - ecco_daily_tag = True\n",
    "    - delta_time_tag = '5tstep'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "439e6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUTURE: we can look at # of events by year for each month (plot one map for each month) - area covered by MHWs\n",
    "# 1 figure for Janaury:\n",
    "    # subplots for each year:\n",
    "        # number of events that start in that month \n",
    "\n",
    "# 1 figure:\n",
    "    #1 subplot for each year:\n",
    "        # count number of events that start in that year \n",
    "        \n",
    "# using area_mhws_1d plot one panel for each month of the year\n",
    "# in each panel plot the timseries for that month for each year (one line for each year in each plot)\n",
    "\n",
    "# maybe add contributions from different budget terms based on seasons \n",
    "# (same for changes in time keeping in mind different modes of variability (ENSO)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8746b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year_start = 2004  # Define the start year\n",
    "# year_end = 2016  # Define the end year (for ECCO daily,NOT included, will stop the year before this one)\n",
    "\n",
    "# Years indicated in the name of input file\n",
    "year_start_in_filename = 1992  # Define the start year\n",
    "year_end_in_filename = 2018 # Define the end year (for ECCO daily, NOT included, will stop the year before this one)\n",
    "# Years included in the input file\n",
    "year_start_inside_file = 1992  # Define the start year\n",
    "year_end_inside_file = 2017 # Define the end year (for ECCO daily, NOT included, will stop the year before this one)\n",
    "\n",
    "\n",
    "# Years indicated in the name of input file\n",
    "# year_start_in_filename = 1993  # Define the start year\n",
    "# year_end_in_filename = 2016 # Define the end year (for ECCO daily, NOT included, will stop the year before this one)\n",
    "# # Years included in the input file\n",
    "# year_start_inside_file = 1993  # Define the start year\n",
    "# year_end_inside_file = 2016 # Define the end year (for ECCO daily, NOT included, will stop the year before this one)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Years to plots\n",
    "year_start_4plot = 1992 #year_start+1 # +0, +1  # Define the start year\n",
    "year_end_4plot = 2018 #year_end-2 # -0, -2 # Define the end year (for ECCO daily, NOT included, will stop the year before this one)\n",
    "# year_end_4plot = 1994 #year_end-2 # -0, -2 # Define the end year (for ECCO daily, NOT included, will stop the year before this one)\n",
    "\n",
    "\n",
    "# ECCO MONTHLY and OISST and ECCO DAILY SUBSAMPLED (to match other data set temporal extension)\n",
    "# year_start = 1993  # Define the start year\n",
    "# year_end = 2016  # Define the end year\n",
    "\n",
    "# Select the level\n",
    "# lev_or_int = 'zlev00' \n",
    "# lev_or_int = 'zlev01' # JUST FOR ECCO MONTHLY \n",
    "# lev_or_int = 'zlev05' \n",
    "# lev_or_int = 'zlev09' \n",
    "lev_or_int = 'ohc_k0_k5'\n",
    "# lev_or_int = 'oisst'\n",
    "# lev_or_int = 'argo'\n",
    "\n",
    "dataset_tag = 'ECCOv4r4_heat' # argo_ohc15_50 oisst_v2 ECCOv4r4_heat\n",
    "daily_monthly_plot_tag = 'daily' # 'daily', 'monthly'\n",
    "ecco_monthly_tag_field = 'ohc_to50m' # JUST FOR ECCO MONTHLY OHC (ohc_to50m) vs LEVELS (or daily ohc) (heat)\n",
    "ecco_monthly_tag = False # True False\n",
    "ecco_daily_tag = True # False\n",
    "test_peaks_tag = False\n",
    "delta_time_tag = '5tsteps' # '5tsteps' 1 for OISST and ECCO monthly (zlev01), 5 for daily\n",
    "test_data_alignment = False\n",
    "\n",
    "grid_and_save_fields_2plot = True\n",
    "\n",
    "# MHW duration thresholds\n",
    "MHW_duration_min_threshold = 5 # days (new minimum duration for MHW events) # 5, 30\n",
    "MHW_duration_max_threshold = np.inf # days (new maximum duration for MHW events) # 30, np.inf\n",
    "MHW_duration_threshold_tag = str(MHW_duration_min_threshold) + '_' + str(MHW_duration_max_threshold) + '_days'\n",
    "\n",
    "# load_dir = '/Users/jacoposala/Downloads/figures_Nov3_k9/daily/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_daily_temp_zlev0_1992_2018/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_daily_temp_zlev0_2004_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/ECCOv4r4_daily_temp_zlev5_1992_2018/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/ECCOv4r4_daily_temp_zlev5_2004_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/ECCOv4r4_daily_temp_zlev9_1992_2018/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/ECCOv4r4_daily_temp_zlev9_2004_2016/output/figures/'\n",
    "load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_heat_daily_temp_ohc_k0_k5_1992_2018/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_daily_temp_ohc_k0_k5_2004_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/OISST_1993_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/OISST_2004_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_monthly_temp_zlev0_2004_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_monthly_temp_zlev0_1993_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/Argo_2004_2016/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/peaks_test_ECCOv4r4_daily_temp_ohc_k0_k5_1992_2018/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_monthly_temp_ohc_to50m_1993_2016_k0_k5/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/ECCOv4r4_monthly_temp_ohc_to50m_1993_2016_k0_k5/output/figures/'\n",
    "# load_dir = '/Users/jacoposala/Downloads/Blanca_Outputs/ECCOv4r4_monthly_temp_ohc_to50m_2004_2016_k0_k5/output/figures/'\n",
    "\n",
    "ECCO_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/'\n",
    "save_dir = join(ECCO_dir,'outputs')\n",
    "path = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/outputs/nc_files_zlev_or_zint/'\n",
    "save_path = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/summary_maps/' + lev_or_int + '/'\n",
    "gridded_path = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/gridded_vars/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39616532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many time stamps to ignore?\n",
    "if year_start_inside_file != year_start_4plot or year_end_inside_file != year_end_4plot:\n",
    "\n",
    "    if dataset_tag=='ECCOv4r4_heat' and daily_monthly_plot_tag=='daily':\n",
    "        sdate = date(year_start_inside_file,1,2)   # start date\n",
    "        edate = date(year_end_inside_file,12,31)   # end date\n",
    "        time = pandas.date_range(sdate,edate-timedelta(days=1),freq='d')\n",
    "        time_mask = np.logical_and(time.year>=year_start_4plot, time.year<=year_end_4plot)\n",
    "        ind_time_start_slice = str(np.where(time_mask)[0][0])\n",
    "        ind_time_end_slice = str(np.where(time_mask)[0][-1])\n",
    "else:\n",
    "    ind_time_start_slice = '0'\n",
    "    ind_time_end_slice = '-1'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff0e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0f310fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECCO\n",
    "if dataset_tag == 'ECCOv4r4_heat':\n",
    "    # Load ECCO grid data\n",
    "    XC_lon = xr.open_dataset(path + 'ECCOv4r4_XC_lon_1993_2017.nc')\n",
    "    YC_lat = xr.open_dataset(path + 'ECCOv4r4_YC_lat_1993_2017.nc')\n",
    "    Z_depth = xr.open_dataset(path + 'ECCOv4r4_Z_depth_1993_2017.nc')\n",
    "    # ECCO daily files\n",
    "    if ecco_daily_tag:\n",
    "        # OHC\n",
    "        if lev_or_int == 'ohc_k0_k5':\n",
    "            file_path = load_dir + f'ECCOv4r4_heat_daily_{year_start_in_filename}_{year_end_in_filename}_prcnt90_noTrend_minLen_5tsteps_withAVE.mat'\n",
    "        # Heat budget terms\n",
    "        else:\n",
    "            file_path = load_dir + f'ECCOv4r4_heat_{lev_or_int}_daily_{year_start_in_filename}_{year_end_in_filename}_prcnt90_noTrend_minLen_5tsteps_withAVE.mat'\n",
    "    # ECCO monthly files\n",
    "    if ecco_monthly_tag:\n",
    "        if ecco_monthly_tag_field == 'ohc_to50m':\n",
    "            file_path = load_dir + f'ECCOv4r4_{ecco_monthly_tag_field}_{lev_or_int}_{year_start_in_filename}_{year_end_in_filename}_prcnt90_noTrend_minLen_1tsteps_withAVE.mat'\n",
    "        else:\n",
    "            file_path = load_dir + f'ECCOv4r4_heat_{lev_or_int}_{year_start_in_filename}_{year_end_in_filename}_prcnt90_noTrend_minLen_1tsteps_withAVE.mat'\n",
    "\n",
    "# Argo\n",
    "elif dataset_tag == 'argo_ohc15_50':\n",
    "    file_path = load_dir + f'argo_ohc15_50_{year_start_in_filename}_{year_end_in_filename}_prcnt90_noTrend_minLen_1tsteps_withAVE.mat'\n",
    "\n",
    "    # Lat/lon\n",
    "    XC_lon = np.arange(20.5, 380.5)  # Similar to MATLAB's [20.5:379.5]'\n",
    "    YC_lat = np.arange(-89.5, 90.5)  # Similar to MATLAB's [-89.5:89.5]'\n",
    "\n",
    "# OISST\n",
    "elif dataset_tag == 'oisst_v2':\n",
    "    file_path = load_dir + f'oisst_v2_{year_start_in_filename}_{year_end_in_filename}_prcnt90_noTrend_minLen_1tsteps_withAVE.mat'\n",
    "    # Load OISST file that includes lat/lon values\n",
    "    oisst_dataset = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/OISSTv2/DATA/sst.mon.mean.nc')\n",
    "    XC_lon = oisst_dataset.lon.values\n",
    "    YC_lat = oisst_dataset.lat.values\n",
    "\n",
    "       \n",
    "# Load the data selected above\n",
    "mat_data = h5py.File(file_path, 'r')\n",
    "\n",
    "# List the keys in the file\n",
    "# print(\"Keys in the file:\", list(mat_data.keys()))\n",
    "\n",
    "# Access the data under the key '#refs#'\n",
    "refs_data = mat_data['#refs#']\n",
    "\n",
    "# Access the data under the key 'find_MHWs_info'\n",
    "find_mhws_info_data = mat_data['find_MHWs_info']\n",
    "\n",
    "# List the keys in the file find_MHWs_info'\n",
    "# print(find_mhws_info_data.keys())\n",
    "\n",
    "# Calculate the duration of the decline pahse (as a difference between the total duration and the duration of the onset phase)\n",
    "decline_duration_in_tsteps = find_mhws_info_data['events_duration_in_tsteps'].value - find_mhws_info_data['onset_duration_in_tsteps'].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d771ae7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['G_advection_declineAve', 'G_advection_eventAve', 'G_advection_onsetAve', 'G_diffusion_declineAve', 'G_diffusion_eventAve', 'G_diffusion_onsetAve', 'G_forcing_declineAve', 'G_forcing_eventAve', 'G_forcing_onsetAve', 'G_total_declineAve', 'G_total_eventAve', 'G_total_onsetAve', 'adv_vConv_declineAve', 'adv_vConv_eventAve', 'adv_vConv_onsetAve', 'data_mhw_tstep_msk', 'data_percentile3d', 'data_used4MHWs', 'data_used4MHWs_declineAve', 'data_used4MHWs_eventAve', 'data_used4MHWs_onsetAve', 'delta_tstep', 'dif_vConv_declineAve', 'dif_vConv_eventAve', 'dif_vConv_onsetAve', 'end_tstep', 'end_tstep_stored_at_peak', 'events_duration_in_tsteps', 'events_number', 'flag_remove_trend', 'onset_duration_in_tsteps', 'peak_tstep', 'peak_tstep_msk', 'peak_value', 'percentile', 'start_tstep', 'start_tstep_msk', 'years']>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_mhws_info_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a88a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load_path = f'/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/metadata/'\n",
    "load_path = '/Users/jacoposala/Downloads/'\n",
    "# Load metadata\n",
    "ECCO_metadata = ['XC_lon', 'YC_lat', 'Z_depth', 'vol', 'area']\n",
    "\n",
    "# Create a dictionary to store the variables\n",
    "ecco_data = {}\n",
    "for ivar in ECCO_metadata:\n",
    "    file_path = f\"{load_path}/ECCOv4r4_{ivar}_1993_2017.nc\"\n",
    "    # Open the dataset and store it in the dictionary\n",
    "    ecco_data[ivar] = xr.open_dataset(file_path)\n",
    "    \n",
    "# Access the variables using the dictionary\n",
    "XC_lon = ecco_data['XC_lon']\n",
    "YC_lat = ecco_data['YC_lat']\n",
    "Z_depth = ecco_data['Z_depth']\n",
    "vol = ecco_data['vol']\n",
    "area = ecco_data['area']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "309336b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data from Matlab output\n",
    "data_used4MHWs = find_mhws_info_data['data_used4MHWs'].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba5534f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice time for data from Matlab output\n",
    "data_used4MHWs_sel = data_used4MHWs[eval(ind_time_start_slice):eval(ind_time_end_slice)+1, :, :]\n",
    "\n",
    "time_sel = time[eval(ind_time_start_slice):eval(ind_time_end_slice)+1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a508583c",
   "metadata": {},
   "source": [
    "### Onset calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35f214a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape 2d 9495x(8100x13) peak_tstep_2d start_tstep_msk_2d\n",
    "\n",
    "# onset_mask = deep copy start_tstep_msk_2d\n",
    "\n",
    "# for loop over time\n",
    "# for each timestep i_t, loop through those point where start_tstep_msk_2d[i_t,:] == 1 \n",
    "# for each of these points ix, assign onset_mask[i_t:peak_tstep_2d[i_t,ix]+1,ix] = 1 \n",
    "\n",
    "\n",
    "# new item in condition_list: onset\n",
    "# use condition_noMHWs (nan where this is satisfied)\n",
    "\n",
    "# for decline, use condiiton_noMHWS and onset to find decline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61762493",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_onset_tag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87703d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_onset_tag:\n",
    "    # Define data needed from Matlab output\n",
    "    peak_tstep = find_mhws_info_data['peak_tstep'].value\n",
    "    start_tstep_msk = find_mhws_info_data['start_tstep_msk'].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f881892",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_onset_tag:\n",
    "    # Slice time \n",
    "    peak_tstep_sel = peak_tstep[eval(ind_time_start_slice):eval(ind_time_end_slice)+1, :, :]\n",
    "    start_tstep_msk_sel = start_tstep_msk[eval(ind_time_start_slice):eval(ind_time_end_slice)+1, :, :]\n",
    "\n",
    "    # Reshape the arrays to 2d\n",
    "    peak_tstep_2d = peak_tstep_sel.reshape((np.shape(time_sel)[0], 13*8100))\n",
    "    start_tstep_msk_2d = start_tstep_msk_sel.reshape((np.shape(time_sel)[0], 13*8100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ae41776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if save_onset_tag:\n",
    "    # Create a mask for onset\n",
    "    # Replace NaN values with -1\n",
    "    peak_tstep_2d[np.isnan(peak_tstep_2d)] = -1\n",
    "    onset_mask = copy.deepcopy(start_tstep_msk_2d)\n",
    "\n",
    "    # Now, proceed with the slicing operation\n",
    "    for i_t in range(peak_tstep_2d.shape[0]):\n",
    "        current_datetime = datetime.now()\n",
    "        # Print the current datetime\n",
    "        print(\"Current datetime:\", current_datetime)\n",
    "        print('i_t', i_t)\n",
    "        print('-----')\n",
    "        for ix in range(peak_tstep_2d.shape[1]):\n",
    "            if start_tstep_msk_2d[i_t, ix] == 1:\n",
    "                onset_mask[i_t:int(peak_tstep_2d[i_t, ix]) + 1, ix] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffbb48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_onset_tag:\n",
    "    onset_mask_3d = onset_mask.reshape((np.shape(time_sel)[0], 13, 8100))\n",
    "    condition_onset = onset_mask_3d.astype(bool)\n",
    "    np.save(f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/condition_onset_{dataset_tag}_{daily_monthly_plot_tag}_{lev_or_int}_{year_start_4plot}_{year_end_4plot}.npy', onset_mask_3d)\n",
    "else:\n",
    "    condition_onset = np.load(f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/condition_onset_{dataset_tag}_{daily_monthly_plot_tag}_{lev_or_int}_{year_start_4plot}_{year_end_4plot}.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216dc820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee456562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition_onset = condition_onset != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf5f491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_metadata_2_variable(xr_meta, np_array_data):\n",
    "#     print(type(xr_meta))\n",
    "    meta_reshaped = xr_meta.reshape(np_array_data.shape[1], np_array_data.shape[2])\n",
    "    meta_reshaped = np.repeat(np.expand_dims(meta_reshaped, axis=2), np_array_data.shape[0], axis=2)\n",
    "    meta_reshaped = meta_reshaped.transpose(2, 0, 1)\n",
    "    return(meta_reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974d6ef8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "XC_lon_input = XC_lon.XC_lon.values\n",
    "YC_lat_input = YC_lat.YC_lat.values\n",
    "area_input = area.area.values\n",
    "XC_lon_reshaped = reshape_metadata_2_variable(xr_meta=XC_lon_input, np_array_data=data_used4MHWs_sel)\n",
    "YC_lat_reshaped = reshape_metadata_2_variable(xr_meta=YC_lat_input, np_array_data=data_used4MHWs_sel)\n",
    "area_reshaped = reshape_metadata_2_variable(xr_meta=area_input, np_array_data=data_used4MHWs_sel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e18e7c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(XC_lon_reshaped[0,:,:].flatten(), YC_lat_reshaped[0,:,:].flatten(), 5, data_used4MHWs_sel[0,:,:].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ed127c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area_tot = np.sum(area.area.values.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c6feebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_save_vars_input_tag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75d230e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_and_save_vars_input_tag is: False\n",
      "loading G_advection\n",
      "loading G_diffusion\n",
      "loading G_forcing\n"
     ]
    }
   ],
   "source": [
    "varnames_load = ['G_advection', 'G_diffusion', 'G_forcing']\n",
    "varnames = ['G_advection', 'G_diffusion', 'G_forcing']\n",
    "\n",
    "if load_and_save_vars_input_tag:\n",
    "    print('load_and_save_vars_input_tag is: ' + str(load_and_save_vars_input_tag))\n",
    "    # Create a dictionary to store the datasets for each variable - FOR SINGLE LEVELS\n",
    "    datasets = {}\n",
    "    years = np.arange(year_start_4plot, year_end_4plot+1)\n",
    "\n",
    "    for ivar_load, ivar in zip(varnames_load, varnames):\n",
    "        var_data = []\n",
    "        path_for_load = '/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/nc_files_zlev_or_zint'\n",
    "    #     for year in years:\n",
    "    #         print(year)\n",
    "        file_path = f'{path_for_load}/ECCOv4r4_{ivar_load}_{lev_or_int}_{year_start_in_filename}_{year_end_in_filename}.nc'\n",
    "\n",
    "        dataset = xr.open_dataset(file_path)\n",
    "\n",
    "        print('done: load')\n",
    "    #     if year >= 2004 and ivar_load == 'G_advection': \n",
    "    #         ivar = ivar_load \n",
    "    #         dataset_box = dataset[ivar+'_cut'].where(lat_lon_bounds, np.nan)\n",
    "    #     elif year>= 2004 and ivar_load == 'G_diffusion':\n",
    "    #         ivar = ivar_load\n",
    "    #         dataset_box = dataset[ivar+'_cut'].where(lat_lon_bounds, np.nan)\n",
    "    #     else:\n",
    "        dataset_box = dataset[ivar + '_' + lev_or_int]#.where(lat_lon_bounds, np.nan)\n",
    "        print('done: box')\n",
    "        var_data.append(dataset_box)\n",
    "\n",
    "        # Concatenate the datasets along the time dimension\n",
    "        var_dataset = xr.concat(var_data, dim='time')\n",
    "\n",
    "        # Store the variable dataset in the dictionary\n",
    "        datasets[ivar_load] = var_dataset\n",
    "\n",
    "        # Save the dataset as a NetCDF file\n",
    "        output_path = f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/lineplots_input_{ivar_load}_{lev_or_int}_dataset.nc'  # Replace with your desired output path\n",
    "        var_dataset.to_netcdf(output_path)\n",
    "        print(f'Saved dataset for {ivar_load}')\n",
    "\n",
    "        dataset.close()\n",
    "        \n",
    "else:\n",
    "    datasets = {}\n",
    "    print('load_and_save_vars_input_tag is: ' + str(load_and_save_vars_input_tag))\n",
    "    \n",
    "    # Define the paths of the saved files\n",
    "    output_paths = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/'\n",
    "    # Create an empty dictionary to store the loaded datasets\n",
    "    loaded_datasets = {}\n",
    "\n",
    "    # Load the datasets\n",
    "    for ivar in varnames_load:\n",
    "        var_data = []\n",
    "\n",
    "        # Open the dataset\n",
    "        dataset_load = xr.open_dataset(output_paths + f'lineplots_input_{ivar}_{lev_or_int}_dataset.nc')\n",
    "        print('loading ' + ivar)\n",
    "\n",
    "        dataset = dataset_load[ivar + '_' + lev_or_int]\n",
    "\n",
    "        var_data.append(dataset)\n",
    "\n",
    "        var_dataset = xr.concat(var_data, dim='time')\n",
    "\n",
    "        datasets[ivar] = var_dataset\n",
    "\n",
    "        # Store the dataset in the dictionary\n",
    "    #     loaded_datasets[ivar] = dataset[ivar + '_' + lev_or_int]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "077ddc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_used4MHWs < data_percentile3d -> nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52b317a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolor(find_mhws_info_data['data_used4MHWs'].value[1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d601edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = 'data_used4MHWs'\n",
    "# data2plot = data_used4MHWs[0,:,:]\n",
    "# plot_map_from_scattered_TEST(XC_lon, YC_lat, data2plot, key, year_start, year_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8451adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = 'data_used4MHWs'\n",
    "# data2plot = find_mhws_info_data['data_used4MHWs'][1,:,:]\n",
    "# plot_map_from_scattered_TEST(XC_lon, YC_lat, data2plot, key, year_start, year_end, stat_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2e272c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open full heat budget terms data, use the same mask, caluclate the area for each time step, \n",
    "# where each term is the dominant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf8aebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition for where data_used is larger than data_percentile \n",
    "condition_MHWs = data_used4MHWs_sel > \\\n",
    "find_mhws_info_data['data_percentile3d'].value[eval(ind_time_start_slice):eval(ind_time_end_slice)+1, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff9b51de",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_decline = np.logical_and(condition_MHWs, np.logical_not(condition_onset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2639a036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conditions_events_onset_decline = [condition_decline, condition_onset, condition_MHWs]\n",
    "# conditions_events_onset_decline_names = ['condition_decline', 'condition_onset', 'condition_MHWs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "debb2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_condition_list = []\n",
    "regions_condition_list_GLOBAL = []\n",
    "\n",
    "# GLOBAL\n",
    "regions_condition_list_GLOBAL.append({\"region_name\":'Global'})\n",
    "\n",
    "# GLOBAL NO EQ PACIFIC\n",
    "regions_condition_list_GLOBAL.append({\"lon_min_exclude2\":[130, -180],\n",
    "                   \"lon_max_exclude2\":[180, -140],\n",
    "                   \"lat_min_exclude2\":[-20, -20],\n",
    "                   \"lat_max_exclude2\":[20, 20], \n",
    "                   \"region_name\":'Global_no_Eq_Pacific'})\n",
    "\n",
    "# PACIFIC OCEAN (no Equatorial)\n",
    "regions_condition_list.append({\"lon_min_exclude2\":[130, -180, 0, -140],\n",
    "                   \"lon_max_exclude2\":[180, -140, 130, 0],\n",
    "                   \"lat_min_exclude2\":[-20, -20, -90, -90],\n",
    "                   \"lat_max_exclude2\":[20, 20, 90, 90], \n",
    "                   \"region_name\":'Pacific_no_Eq'})\n",
    "\n",
    "# INDIAN OCEAN\n",
    "regions_condition_list.append({\"lon_min\":20,\n",
    "                   \"lon_max\":146,\n",
    "                   \"lat_min\":-60,\n",
    "                   \"lat_max\":30, \n",
    "                   \"region_name\":'Indian'})\n",
    "\n",
    "# ATLANTIC OCEAN\n",
    "regions_condition_list.append({\"lon_min\":-80,\n",
    "                   \"lon_max\":-10,\n",
    "                   \"lat_min\":-90,\n",
    "                   \"lat_max\":90, \n",
    "                   \"region_name\":'Atlantic'})\n",
    "\n",
    "# SWP \n",
    "# regions_condition_list.append({\"lon_min\":-170.5,\n",
    "#                    \"lon_max\":-140.5,\n",
    "#                    \"lat_min\":-45.5,\n",
    "#                    \"lat_max\":-25.5, \n",
    "#                    \"region_name\":'SWP'})\n",
    "\n",
    "# # NEP \n",
    "# regions_condition_list.append({\"lon_min\":-150.5,\n",
    "#                    \"lon_max\":-134.5,\n",
    "#                    \"lat_min\":39.5,\n",
    "#                    \"lat_max\":50.5, \n",
    "#                    \"region_name\":'NEP'})\n",
    "                              \n",
    "# #TASMAN\n",
    "# regions_condition_list.append({\"lon_min\":147,\n",
    "#                    \"lon_max\":155,\n",
    "#                    \"lat_min\":-45,\n",
    "#                    \"lat_max\":-37, \n",
    "#                    \"region_name\":'TASMAN'})\n",
    "\n",
    "\n",
    "\n",
    "# regions_condition_list_names = ['Global', 'noEq_Pac', 'Pacific', 'SWP', 'NEP', 'TASMAN']\n",
    "# budget_condition_list_names = ['MHWs', 'MHWs, Forcing > Advection', \n",
    "#                                'MHWs, Forcing > Diffusion', \n",
    "#                                'MHWs, Advection > Diffusion', \n",
    "#                                'MHWs, Forcing > Advection and Diffusion'] \n",
    "# # budget_condition_list_names = ['MHWs', 'MHWs, Forcing > Advection'] \n",
    "# budget_condition_list_names = ['MHWs', 'Forcing > 0'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c9ca061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_array_to_condition_list(array_input, ind_time_start_slice, ind_time_end_slice):\n",
    "    arr = array_input.values\n",
    "    # Reshape the other elements\n",
    "    reshaped_array = np.reshape(arr, (arr.shape[0], arr.shape[1], -1))\n",
    "\n",
    "    # Slice along the time dimension only for the second element\n",
    "    sliced_array = reshaped_array[eval(ind_time_start_slice):eval(ind_time_end_slice) + 1, :, :]\n",
    "\n",
    "    return(sliced_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ef32561",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_list = []\n",
    "condition_list.append({\"phase_mhw\":condition_MHWs, \"budget_condition\":[], \"tag\":'MHW_all'})\n",
    "\n",
    "################ FORCING ###########################################################################\n",
    "bfr = reshape_array_to_condition_list(array_input = datasets['G_forcing'] > 0, \\\n",
    "                                      ind_time_start_slice = ind_time_start_slice, \\\n",
    "                                      ind_time_end_slice = ind_time_end_slice)\n",
    "condition_list.append({\"phase_mhw\":condition_onset, \"budget_condition\":bfr, \"tag\":'MHW_onset_forcing_pos'})\n",
    "\n",
    "bfr = reshape_array_to_condition_list(array_input = datasets['G_forcing'] < 0, \\\n",
    "                                      ind_time_start_slice = ind_time_start_slice, \\\n",
    "                                      ind_time_end_slice = ind_time_end_slice)\n",
    "condition_list.append({\"phase_mhw\":condition_decline, \"budget_condition\":bfr, \"tag\":'MHW_decline_forcing_neg'})\n",
    "\n",
    "# ################# ADVECTION ###########################################################################\n",
    "# bfr = reshape_array_to_condition_list(array_input = datasets['G_advection'] > 0, \\\n",
    "#                                       ind_time_start_slice = ind_time_start_slice, \\\n",
    "#                                       ind_time_end_slice = ind_time_end_slice)\n",
    "# condition_list.append({\"phase_mhw\":condition_onset, \"budget_condition\":bfr, \"tag\":'MHW_onset_advection_pos'})\n",
    "\n",
    "# bfr = reshape_array_to_condition_list(array_input = datasets['G_advection'] < 0, \\\n",
    "#                                       ind_time_start_slice = ind_time_start_slice, \\\n",
    "#                                       ind_time_end_slice = ind_time_end_slice)\n",
    "# condition_list.append({\"phase_mhw\":condition_decline, \"budget_condition\":bfr, \"tag\":'MHW_decline_advection_neg'})\n",
    "\n",
    "# ################# DIFFUSION ###########################################################################\n",
    "# bfr = reshape_array_to_condition_list(array_input = datasets['G_advection'] > 0, \\\n",
    "#                                       ind_time_start_slice = ind_time_start_slice, \\\n",
    "#                                       ind_time_end_slice = ind_time_end_slice)\n",
    "# condition_list.append({\"phase_mhw\":condition_onset, \"budget_condition\":bfr, \"tag\":'MHW_onset_advection_pos'})\n",
    "\n",
    "# bfr = reshape_array_to_condition_list(array_input = datasets['G_advection'] < 0, \\\n",
    "#                                       ind_time_start_slice = ind_time_start_slice, \\\n",
    "#                                       ind_time_end_slice = ind_time_end_slice)\n",
    "# condition_list.append({\"phase_mhw\":condition_decline, \"budget_condition\":bfr, \"tag\":'MHW_decline_advection_neg'})\n",
    "\n",
    "# budget_condition_list.append(datasets['G_forcing'] < 0) \n",
    "# budget_condition_list.append(np.abs(datasets['G_forcing']) > np.abs(datasets['G_advection'])) \n",
    "# budget_condition_list.append(np.abs(datasets['G_forcing']) > np.abs(datasets['G_diffusion'])) \n",
    "# budget_condition_list.append(np.abs(datasets['G_advection']) > np.abs(datasets['G_diffusion'])) \n",
    "# budget_condition_list.append(\n",
    "#     (datasets['G_forcing']>0) &\n",
    "#     (datasets['G_forcing']) > (datasets['G_advection']) &\n",
    "#     ((datasets['G_forcing']) > (datasets['G_diffusion']))\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38518e1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MHW_all', 'MHW_onset_forcing_pos', 'MHW_decline_forcing_neg']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[\"tag\"] for x in condition_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1d57ba06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pacific_no_Eq', 'Indian', 'Atlantic']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[\"region_name\"] for x in regions_condition_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f72919d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Global', 'Global_no_Eq_Pacific']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[\"region_name\"] for x in regions_condition_list_GLOBAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f73dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to check if masks onset and decline were calculated correctly (showing onset, decline, peak, percentile and data)\n",
    "\n",
    "# datapercentile_threshold = find_mhws_info_data['data_percentile3d'].value[eval(ind_time_start_slice):eval(ind_time_end_slice)+1, :, :]\n",
    "\n",
    "# plt.figure(figsize = (12,5))\n",
    "# plt.plot(time_sel, data_used4MHWs_sel[:,1,1], label = 'data')\n",
    "# plt.plot(time_sel, datapercentile_threshold[:,1,1], label = 'threshold')\n",
    "# plt.plot(time_sel[condition_onset[:,1,1]], data_used4MHWs_sel[:,1,1][condition_onset[:,1,1]], '*', label = 'onset')\n",
    "# plt.plot(time_sel[condition_decline[:,1,1]], data_used4MHWs_sel[:,1,1][condition_decline[:,1,1]], 'o', label = 'decline')\n",
    "# start_date = datetime(1992, 12, 1)\n",
    "# end_date = datetime(1993, 1, 15 )\n",
    "# plt.xlim(start_date, end_date)\n",
    "# plt.xlabel('Time', fontsize = 12)\n",
    "# plt.ylabel('Data', fontsize = 12)\n",
    "# plt.ylim([0,35])\n",
    "# plt.legend(fontsize = 12)\n",
    "# plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28a208e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ciao' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-953ed62a3246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mciao\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ciao' is not defined"
     ]
    }
   ],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e6cc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96058dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e9e7a07",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91198e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition: MHW_all\n",
      "starting copy\n",
      "ending copy\n",
      "done ireg: Global\n",
      "done ireg: Global_no_Eq_Pacific\n",
      "done icondition iteration\n",
      "Condition: MHW_onset_forcing_pos\n",
      "starting copy\n",
      "ending copy\n"
     ]
    }
   ],
   "source": [
    "bfr_area_results_GLOBAL = {}\n",
    "\n",
    "for i, icondition in enumerate(condition_list):\n",
    "    print('Condition: ' + icondition[\"tag\"])\n",
    "    condition = icondition[\"phase_mhw\"]\n",
    "    ibudget = icondition[\"budget_condition\"]\n",
    "    iname = icondition[\"tag\"]\n",
    "\n",
    "    print('starting copy')\n",
    "    \n",
    "    bfr_area_reshaped = np.copy(area_reshaped)\n",
    "    bfr_area_reshaped[np.isnan(data_used4MHWs_sel)] = 0 # CHECK THIS - NOT WORKING NOW\n",
    "    \n",
    "    bfr_area_reshaped_copy = np.copy(bfr_area_reshaped)\n",
    "    \n",
    "    print('ending copy')\n",
    "    \n",
    "    if condition != []:\n",
    "        bfr_area_reshaped[~condition] = 0\n",
    "    if ibudget != []:\n",
    "        bfr_area_reshaped[~ibudget] = 0\n",
    "    \n",
    "    \n",
    "    for ireg in regions_condition_list_GLOBAL:\n",
    "        bfr_area_reshaped_reg = np.copy(bfr_area_reshaped)\n",
    "        bfr_area_reshaped_copy_reg = np.copy(bfr_area_reshaped_copy)\n",
    "\n",
    "#         if ireg['region_name'] is not 'Global':\n",
    "        # for regions to keep\n",
    "        if 'lon_min' in ireg.keys():\n",
    "            bfr_area_reshaped_reg[XC_lon_reshaped < ireg[\"lon_min\"]] = 0\n",
    "            bfr_area_reshaped_reg[XC_lon_reshaped > ireg[\"lon_max\"]] = 0\n",
    "            bfr_area_reshaped_reg[YC_lat_reshaped < ireg[\"lat_min\"]] = 0\n",
    "            bfr_area_reshaped_reg[YC_lat_reshaped > ireg[\"lat_max\"]] = 0\n",
    "\n",
    "            bfr_area_reshaped_copy_reg[XC_lon_reshaped < ireg[\"lon_min\"]] = 0\n",
    "            bfr_area_reshaped_copy_reg[XC_lon_reshaped > ireg[\"lon_max\"]] = 0\n",
    "            bfr_area_reshaped_copy_reg[YC_lat_reshaped < ireg[\"lat_min\"]] = 0\n",
    "            bfr_area_reshaped_copy_reg[YC_lat_reshaped > ireg[\"lat_max\"]] = 0             \n",
    "\n",
    "        # for regions to exclude    \n",
    "        elif 'lon_min_exclude2' in ireg.keys():\n",
    "            for ix in np.arange(0, len(ireg['lon_min_exclude2']), 1):\n",
    "                bfr_area_reshaped_reg[np.logical_and(\n",
    "                    np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "                                   XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "                    np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "                                   YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))] = 0 \n",
    "\n",
    "\n",
    "                bfr_area_reshaped_copy_reg[np.logical_and(\n",
    "                    np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "                                   XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "                    np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "                                   YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))] = 0\n",
    "        print('done ireg: ' + ireg['region_name'])\n",
    "        \n",
    "        bfr_area_tot = np.sum(bfr_area_reshaped_copy_reg.flatten())\n",
    "        bfr_area_reshaped_reg_1d_2plot = np.sum(bfr_area_reshaped_reg.reshape(bfr_area_reshaped_reg.shape[0], -1), axis=1)\n",
    "    \n",
    "        # create list with bfr_area_reshaped_reg_1d_2plot and bfr_area_tot for each region\n",
    "        # Store the results for the current region with a unique name\n",
    "        region_name = ireg['region_name']\n",
    "        bfr_area_results_GLOBAL[icondition['tag'] + '_' + region_name + \"_bfr_area_reshaped_reg_1d_2plot\"] = bfr_area_reshaped_reg_1d_2plot\n",
    "        bfr_area_results_GLOBAL[icondition['tag'] + '_' + region_name + \"_bfr_area_tot\"] = bfr_area_tot\n",
    "#         bfr_area_results_GLOBAL['condition_list'] = condition_list[i]\n",
    "        path2saveinfo4plots = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/summary_maps/area_covered/'\n",
    "        np.save(path2saveinfo4plots + f'info4plots_{icondition[\"tag\"]}_{region_name}.npy', bfr_area_results_GLOBAL)\n",
    "        \n",
    "        del bfr_area_tot, bfr_area_reshaped_reg, bfr_area_reshaped_copy_reg\n",
    "    del bfr_area_reshaped, bfr_area_reshaped_copy, condition, ibudget, iname\n",
    "    print('done icondition iteration')\n",
    "    \n",
    "    \n",
    "#         ciao\n",
    "        # in another cell: plot\n",
    "#         ciao\n",
    "        # Loop through subplots and time subsets\n",
    "#         for i, subplot in enumerate(axes):\n",
    "#             # Define start and end indices for the current time subset\n",
    "#             start_index = i * time_interval\n",
    "#             end_index = start_index + time_interval - 1\n",
    "\n",
    "# #             scaling_factor = np.nanmax(area_mhws_1d/area_tot * 100)\n",
    "# #             scaling_factor_str = str('{0:.2f}'.format(scaling_factor))\n",
    "\n",
    "#             subplot.plot(time[start_index:end_index+1],\n",
    "#                          (bfr_area_reshaped_reg_1d_2plot[start_index:end_index+1]/bfr_area_tot * 100), label=ireg['region_name'] + ' ('  + ')')\n",
    "\n",
    "#             print('done plot')\n",
    "\n",
    "#             legend_labels.append(ireg['region_name'] + ' ('  + ')')\n",
    "\n",
    "#             # Customize the subplot (e.g., title, labels)\n",
    "#             subplot.set_title(f'Time period: {time[start_index]} - {time[end_index]}', fontsize=12)\n",
    "#             subplot.set_xlabel('Time', fontsize=12)\n",
    "#             subplot.set_ylabel('%', fontsize=12)\n",
    "#             print('done title etc')\n",
    "\n",
    "#         # Common title and legend for the entire figure\n",
    "#         fig.suptitle(f'Percentage of area covered by MHWs - {iname}', fontsize=16)\n",
    "#         fig.legend(loc='lower center', bbox_to_anchor=(0.5, 0), ncol=3, labels=legend_labels)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622d5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bfr_area_results_GLOBAL.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(bfr_area_results_GLOBAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53d2d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bfr_area_results_GLOBAL['MHW_onset_forcing_pos_Global_bfr_area_reshaped_reg_1d_2plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bfr_area_results_GLOBAL['MHW_onset_forcing_pos_Global_bfr_area_reshaped_reg_1d_2plot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c29e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store legend labels\n",
    "legend_labels = {}\n",
    "\n",
    "# Loop through each condition\n",
    "for i, icondition in enumerate(condition_list):\n",
    "    print(icondition[\"tag\"])\n",
    "    condition_name = icondition[\"tag\"]\n",
    "\n",
    "    # Define the number of subplots (rows)\n",
    "    num_subplots = 5\n",
    "\n",
    "    # Calculate the time step interval for each subplot (assuming equal intervals)\n",
    "    time_interval = int(len(time) / num_subplots)\n",
    "\n",
    "    # Create a figure with 5 subplots\n",
    "    fig, axes = plt.subplots(num_subplots, 1, figsize=(20, 12))\n",
    "    fig.subplots_adjust(hspace=0.6)\n",
    "\n",
    "    # Loop through subplots and time subsets\n",
    "    for j, subplot in enumerate(axes):\n",
    "        # Define start and end indices for the current time subset\n",
    "        start_index = j * time_interval\n",
    "        end_index = start_index + time_interval - 1\n",
    "\n",
    "        # Plot data for each region\n",
    "        for region_name, bfr_area_reshaped_reg_1d_2plot in bfr_area_results.items():\n",
    "            # Check if the region name contains the condition name and the specific plot data\n",
    "            if condition_name in region_name and \"bfr_area_reshaped_reg_1d_2plot\" in region_name:\n",
    "                # Extract the total area for normalization\n",
    "                total_area_key = region_name.replace(\"_reshaped_reg_1d_2plot\", \"_tot\")\n",
    "                total_area = bfr_area_results.get(total_area_key, 1)  # Default to 1 if not found to avoid division by zero\n",
    "                # Plot the data\n",
    "                subplot.plot(time[start_index:end_index+1],\n",
    "                             (bfr_area_results[region_name][start_index:end_index+1] / total_area * 100),\n",
    "                             label=region_name.replace(f\"_{condition_name}_bfr_area_reshaped_reg_1d_2plot\", \"\"))\n",
    "\n",
    "                # Add legend label to the list if not already added\n",
    "                if region_name.replace(f\"_{condition_name}_bfr_area_reshaped_reg_1d_2plot\", \"\") not in legend_labels:\n",
    "                    legend_labels[region_name.replace(f\"_{condition_name}_bfr_area_reshaped_reg_1d_2plot\", \"\")] = condition_name\n",
    "\n",
    "        # Customize the subplot (e.g., title, labels)\n",
    "        subplot.set_title(f'Time period: {time[start_index]} - {time[end_index]}', fontsize=12)\n",
    "        subplot.set_xlabel('Time', fontsize=12)\n",
    "        subplot.set_ylabel('%', fontsize=12)\n",
    "        fig.subplots_adjust(top=0.93)\n",
    "\n",
    "    # Common title and legend for the entire figure\n",
    "    fig.suptitle(f'Percentage of area covered by MHWs - {condition_name}', fontsize=16)\n",
    "\n",
    "    # Create common legend with the same colors as the plot\n",
    "    handles, labels = [], []\n",
    "    for label, condition_name in legend_labels.items():\n",
    "        # Find the first line with the label and extract its color\n",
    "        for line in axes[0].lines:\n",
    "            if line.get_label() == label:\n",
    "                color = line.get_color()\n",
    "                break\n",
    "        handles.append(plt.Line2D([0], [0], linestyle='-', color=color, label=label))\n",
    "        labels.append(label)\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, 0.05), ncol=3)\n",
    "\n",
    "\n",
    "    # Show or save the plot\n",
    "    plt.show()  # or plt.savefig('plot_name.png') to save the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(XC_lon_reshaped[0,:,:].flatten(), YC_lat_reshaped[0,:,:].flatten(), bfr_area_reshaped_copy_reg[0,:,:].flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(XC_lon_reshaped[0,:,:].flatten(), YC_lat_reshaped[0,:,:].flatten(), bfr_area_reshaped_reg[0,:,:].flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c60694",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bfr_area_reshaped_reg_1d_2plot/bfr_area_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3262c85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928cea6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1a1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd53350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# one plot for each budget condition and for each onset/decline/MHWs condition - GLOBAL\n",
    "for i, icondition in enumerate(condition_list):\n",
    "    print(icondition[\"tag\"])\n",
    "    condition = icondition[\"phase_mhw\"]\n",
    "    ibudget = icondition[\"budget_condition\"]\n",
    "\n",
    "    # Define the number of subplots (rows)\n",
    "    num_subplots = 5\n",
    "\n",
    "    # Calculate the time step interval for each subplot (assuming equal intervals)\n",
    "    time_interval = int(len(time) / num_subplots)\n",
    "\n",
    "    # Create a figure with 5 subplots\n",
    "    fig, axes = plt.subplots(num_subplots, 1, figsize=(20, 12))  # Adjust figsize as needed\n",
    "    fig.subplots_adjust(hspace=0.7)  # Adjust as needed\n",
    "\n",
    "    legend_labels = []\n",
    "\n",
    "    print('starting copy')\n",
    "\n",
    "    bfr_data_used4MHWs_sel = copy.deepcopy(data_used4MHWs_sel)\n",
    "    bfr_data_used4MHWs_sel[~condition] = np.nan\n",
    "\n",
    "    if type(ibudget) is not list:\n",
    "        bfr_data_used4MHWs_sel[~ibudget] = np.nan\n",
    "    print('done bfr_data_used4MHWs_sel')\n",
    "\n",
    "    for ireg in regions_condition_list_GLOBAL:\n",
    "        bfr_data_used4MHWs_sel_reg = copy.deepcopy(bfr_data_used4MHWs_sel)\n",
    "\n",
    "        if ireg['region_name'] is not 'Global':\n",
    "            # for regions to keep\n",
    "            if 'lon_min' in ireg.keys():\n",
    "                bfr_data_used4MHWs_sel_reg[XC_lon_reshaped < ireg[\"lon_min\"]] = np.nan\n",
    "                bfr_data_used4MHWs_sel_reg[XC_lon_reshaped > ireg[\"lon_max\"]] = np.nan\n",
    "                bfr_data_used4MHWs_sel_reg[YC_lat_reshaped < ireg[\"lat_min\"]] = np.nan\n",
    "                bfr_data_used4MHWs_sel_reg[YC_lat_reshaped > ireg[\"lat_max\"]] = np.nan\n",
    "            # for regions to exclude    \n",
    "            elif 'lon_min_exclude2' in ireg.keys():\n",
    "                for ix in np.arange(0, len(ireg['lon_min_exclude2']), 1):\n",
    "                    bfr_data_used4MHWs_sel_reg[np.logical_and(\n",
    "                        np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "                                       XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "                        np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "                                       YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))] = np.nan \n",
    "        print('done ireg')\n",
    "\n",
    "        # Loop through subplots and time subsets\n",
    "        for i, subplot in enumerate(axes):\n",
    "            # Define start and end indices for the current time subset\n",
    "            start_index = i * time_interval\n",
    "            end_index = start_index + time_interval - 1\n",
    "\n",
    "            # Subset data for the current time period\n",
    "            bfr_data_subset = bfr_data_used4MHWs_sel_reg[start_index:end_index+1, :]\n",
    "\n",
    "            # Your plotting logic using bfr_data_subset\n",
    "            mhw_mask = np.ones(bfr_data_subset.shape)\n",
    "            mhw_mask[np.isnan(bfr_data_subset)] = 0\n",
    "            print('done mhw_mask')\n",
    "\n",
    "            area_mhws = area_reshaped[start_index:end_index+1, :] * mhw_mask\n",
    "            area_mhws_2d = area_mhws.reshape(bfr_data_subset.shape[0], -1)\n",
    "            area_mhws_1d = np.sum(area_mhws_2d, axis=1)\n",
    "            print('done area')\n",
    "\n",
    "            scaling_factor = np.nanmax(area_mhws_1d/area_tot * 100)\n",
    "            scaling_factor_str = str('{0:.2f}'.format(scaling_factor))\n",
    "\n",
    "            subplot.plot(time[start_index:end_index+1],\n",
    "                         (area_mhws_1d/area_tot * 100) / scaling_factor, label=ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "            print('done plot')\n",
    "\n",
    "            legend_labels.append(ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "\n",
    "            # Customize the subplot (e.g., title, labels)\n",
    "            subplot.set_title(f'Time period: {time[start_index]} - {time[end_index]}', fontsize=12)\n",
    "            subplot.set_xlabel('Time', fontsize=12)\n",
    "            subplot.set_ylabel('%', fontsize=12)\n",
    "            print('done title etc')\n",
    "\n",
    "        # Common title and legend for the entire figure\n",
    "        fig.suptitle(f'Percentage of area covered by MHWs - {ibudget_names} - {condition_name}', fontsize=16)\n",
    "        fig.legend(loc='lower center', bbox_to_anchor=(0.5, 0), ncol=3, labels=legend_labels)\n",
    "#         del bfr_data_used4MHWs_sel\n",
    "#         del area_mhws\n",
    "#         del area_mhws_2d\n",
    "#         del area_mhws_1d\n",
    "#         del mhw_mask\n",
    "#         del bfr_data_subset\n",
    "\n",
    "    # Save the figure\n",
    "#         plt.savefig(f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/area_covered_{ibudget_names}_{condition_name}_subplots.png', dpi=1000)\n",
    "    plt.show()  # Display the figure\n",
    "    plt.close(fig)  # Close the figure to avoid memory issues\n",
    "    print('end figure')\n",
    "ciao\n",
    "# Your original plotting code (excluding the loops) using the full bfr_data_used4MHWs_sel can go here (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a745bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5f3fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # one plot for each budget condition and for each onset/decline/MHWs condition - GLOBAL\n",
    "# for ibudget, ibudget_names in zip(budget_condition_list_reshaped, budget_condition_list_names):\n",
    "#     print('restart')\n",
    "#     print(ibudget_names)\n",
    "#     for condition, condition_name in zip(conditions_events_onset_decline, conditions_events_onset_decline_names):\n",
    "#         print(condition_name)\n",
    "\n",
    "#         # Define the number of subplots (rows)\n",
    "#         num_subplots = 5\n",
    "\n",
    "#         # Calculate the time step interval for each subplot (assuming equal intervals)\n",
    "#         time_interval = int(len(time) / num_subplots)\n",
    "\n",
    "#         # Create a figure with 5 subplots\n",
    "#         fig, axes = plt.subplots(num_subplots, 1, figsize=(20, 12))  # Adjust figsize as needed\n",
    "#         fig.subplots_adjust(hspace=0.7)  # Adjust as needed\n",
    "        \n",
    "#         legend_labels = []\n",
    "\n",
    "#         print('starting copy')\n",
    "        \n",
    "#         bfr_data_used4MHWs_sel = data_used4MHWs_sel.copy()\n",
    "#         bfr_data_used4MHWs_sel[~condition] = np.nan\n",
    "\n",
    "#         if type(ibudget) is not list:\n",
    "#             bfr_data_used4MHWs_sel[~ibudget] = np.nan\n",
    "#         print('done bfr_data_used4MHWs_sel')\n",
    "\n",
    "#         for ireg in regions_condition_list_GLOBAL:\n",
    "        \n",
    "#             if ireg['region_name'] is not 'Global':\n",
    "#                 # for regions to keep\n",
    "#                 if 'lon_min' in ireg.keys():\n",
    "#                     bfr_data_used4MHWs_sel[XC_lon_reshaped < ireg[\"lon_min\"]] = np.nan\n",
    "#                     bfr_data_used4MHWs_sel[XC_lon_reshaped > ireg[\"lon_max\"]] = np.nan\n",
    "#                     bfr_data_used4MHWs_sel[YC_lat_reshaped < ireg[\"lat_min\"]] = np.nan\n",
    "#                     bfr_data_used4MHWs_sel[YC_lat_reshaped > ireg[\"lat_max\"]] = np.nan\n",
    "#                 # for regions to exclude    \n",
    "#                 elif 'lon_min_exclude2' in ireg.keys():\n",
    "#                     for ix in np.arange(0, len(ireg['lon_min_exclude2']), 1):\n",
    "#                         bfr_data_used4MHWs_sel[np.logical_and(\n",
    "#                             np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "#                                            XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "#                             np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "#                                            YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))] = np.nan \n",
    "#             print('done ireg')\n",
    "                        \n",
    "#             # Loop through subplots and time subsets\n",
    "#             for i, subplot in enumerate(axes):\n",
    "#                 # Define start and end indices for the current time subset\n",
    "#                 start_index = i * time_interval\n",
    "#                 end_index = start_index + time_interval - 1\n",
    "\n",
    "#                 # Subset data for the current time period\n",
    "#                 bfr_data_subset = bfr_data_used4MHWs_sel[start_index:end_index+1, :]\n",
    "\n",
    "#                 # Your plotting logic using bfr_data_subset\n",
    "#                 mhw_mask = np.ones(bfr_data_subset.shape)\n",
    "#                 mhw_mask[np.isnan(bfr_data_subset)] = 0\n",
    "#                 print('done mhw_mask')\n",
    "\n",
    "#                 area_mhws = area_reshaped[start_index:end_index+1, :] * mhw_mask\n",
    "#                 area_mhws_2d = area_mhws.reshape(bfr_data_subset.shape[0], -1)\n",
    "#                 area_mhws_1d = np.sum(area_mhws_2d, axis=1)\n",
    "#                 print('done area')\n",
    "\n",
    "#                 scaling_factor = np.nanmax(area_mhws_1d/area_tot * 100)\n",
    "#                 scaling_factor_str = str('{0:.2f}'.format(scaling_factor))\n",
    "\n",
    "#                 subplot.plot(time[start_index:end_index+1],\n",
    "#                              (area_mhws_1d/area_tot * 100) / scaling_factor, label=ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "#                 print('done plot')\n",
    "                \n",
    "#                 legend_labels.append(ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "                    \n",
    "#                 # Customize the subplot (e.g., title, labels)\n",
    "#                 subplot.set_title(f'Time period: {time[start_index]} - {time[end_index]}', fontsize=12)\n",
    "#                 subplot.set_xlabel('Time', fontsize=12)\n",
    "#                 subplot.set_ylabel('%', fontsize=12)\n",
    "#                 print('done title etc')\n",
    "\n",
    "#             # Common title and legend for the entire figure\n",
    "#             fig.suptitle(f'Percentage of area covered by MHWs - {ibudget_names} - {condition_name}', fontsize=16)\n",
    "#             fig.legend(loc='lower center', bbox_to_anchor=(0.5, 0), ncol=3, labels=legend_labels)\n",
    "#             del bfr_data_used4MHWs_sel\n",
    "#             del area_mhws\n",
    "#             del area_mhws_2d\n",
    "#             del area_mhws_1d\n",
    "#             del mhw_mask\n",
    "#             del bfr_data_subset\n",
    "\n",
    "#         # Save the figure\n",
    "# #         plt.savefig(f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/area_covered_{ibudget_names}_{condition_name}_subplots.png', dpi=1000)\n",
    "#         plt.show()  # Display the figure\n",
    "#         plt.close(fig)  # Close the figure to avoid memory issues\n",
    "#         print('end figure')\n",
    "#     ciao\n",
    "#     # Your original plotting code (excluding the loops) using the full bfr_data_used4MHWs_sel can go here (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281aaa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82661707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c28746a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4160790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa85718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a578fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc25b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14b1a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d7870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import copy\n",
    "\n",
    "\n",
    "# # One plot for each combination of ibudget and condition\n",
    "# for ibudget, ibudget_names in zip(budget_condition_list_reshaped, budget_condition_list_names):\n",
    "#     print('restart')\n",
    "#     print(ibudget_names)\n",
    "#     for condition, condition_name in zip(conditions_events_onset_decline, conditions_events_onset_decline_names):\n",
    "#         print(condition_name)\n",
    "\n",
    "#         # Define the number of subplots (rows)\n",
    "#         num_subplots = 5\n",
    "\n",
    "#         # Calculate the time step interval for each subplot (assuming equal intervals)\n",
    "#         time_interval = int(len(time) / num_subplots)\n",
    "\n",
    "#         # Create a figure with 5 subplots\n",
    "#         fig, axes = plt.subplots(num_subplots, 1, figsize=(20, 12))  # Adjust figsize as needed\n",
    "#         fig.subplots_adjust(hspace=0.7)  # Adjust as needed\n",
    "\n",
    "#         legend_labels = []\n",
    "\n",
    "#         bfr_data_used4MHWs_sel_copy = copy.deepcopy(data_used4MHWs_sel)\n",
    "#         bfr_data_used4MHWs_sel_copy[~condition] = np.nan\n",
    "\n",
    "#         if not isinstance(ibudget, list):\n",
    "#             bfr_data_used4MHWs_sel_copy[~ibudget] = np.nan\n",
    "\n",
    "#         for ireg in regions_condition_list_GLOBAL:\n",
    "#             if ireg['region_name'] != 'Global':\n",
    "#                 if 'lon_min' in ireg.keys():\n",
    "#                     bfr_data_used4MHWs_sel_copy[XC_lon_reshaped < ireg[\"lon_min\"]] = np.nan\n",
    "#                     bfr_data_used4MHWs_sel_copy[XC_lon_reshaped > ireg[\"lon_max\"]] = np.nan\n",
    "#                     bfr_data_used4MHWs_sel_copy[YC_lat_reshaped < ireg[\"lat_min\"]] = np.nan\n",
    "#                     bfr_data_used4MHWs_sel_copy[YC_lat_reshaped > ireg[\"lat_max\"]] = np.nan\n",
    "#                 elif 'lon_min_exclude2' in ireg.keys():\n",
    "#                     for ix in range(len(ireg['lon_min_exclude2'])):\n",
    "#                         bfr_data_used4MHWs_sel_copy[\n",
    "#                             np.logical_and(\n",
    "#                                 np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "#                                                XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "#                                 np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "#                                                YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))\n",
    "#                         ] = np.nan\n",
    "\n",
    "#             for i, subplot in enumerate(axes):\n",
    "#                 start_index = i * time_interval\n",
    "#                 end_index = start_index + time_interval - 1\n",
    "\n",
    "#                 bfr_data_subset = bfr_data_used4MHWs_sel_copy[start_index:end_index + 1, :]\n",
    "#                 mhw_mask = np.ones(bfr_data_subset.shape)\n",
    "#                 mhw_mask[np.isnan(bfr_data_subset)] = 0\n",
    "\n",
    "#                 area_mhws = area_reshaped[start_index:end_index + 1, :] * mhw_mask\n",
    "#                 area_mhws_2d = area_mhws.reshape(bfr_data_subset.shape[0], -1)\n",
    "#                 area_mhws_1d = np.sum(area_mhws_2d, axis=1)\n",
    "\n",
    "#                 scaling_factor = np.nanmax(area_mhws_1d / area_tot * 100)\n",
    "#                 scaling_factor_str = str('{0:.2f}'.format(scaling_factor))\n",
    "\n",
    "#                 subplot.plot(time[start_index:end_index + 1],\n",
    "#                              (area_mhws_1d / area_tot * 100) / scaling_factor,\n",
    "#                              label=ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "#                 legend_labels.append(ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "#                 subplot.set_title(f'Time period: {time[start_index]} - {time[end_index]}', fontsize=12)\n",
    "#                 subplot.set_xlabel('Time', fontsize=12)\n",
    "#                 subplot.set_ylabel('%', fontsize=12)\n",
    "\n",
    "#         fig.suptitle(f'Percentage of area covered by MHWs - {ibudget_names} - {condition_name}', fontsize=16)\n",
    "#         fig.legend(loc='lower center', bbox_to_anchor=(0.5, 0), ncol=3, labels=legend_labels)\n",
    "\n",
    "#         plt.show()\n",
    "#         plt.close(fig)\n",
    "#         print('end figure')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0cd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bad923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3c553d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3689fdb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceca9934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a323945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b19e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b20e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20ab26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741b7c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951f020c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d180cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d80763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8adaed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c44ea79",
   "metadata": {},
   "source": [
    "### Plots for Global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca3a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e599560",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one plot for each budget condition and for each onset/decline/MHWs condition - GLOBAL\n",
    "for ibudget, ibudget_names in zip(budget_condition_list_reshaped, budget_condition_list_names):\n",
    "    for condition, condition_name in zip(conditions_events_onset_decline, conditions_events_onset_decline_names):\n",
    "        plt.figure(figsize=(20,8))  # Create a new figure for each combination of budget condition and condition onset\n",
    "        for ireg in regions_condition_list_GLOBAL:\n",
    "            bfr_data_used4MHWs_sel = copy.deepcopy(data_used4MHWs_sel)\n",
    "            bfr_data_used4MHWs_sel[~condition] = np.nan\n",
    "            \n",
    "            if type(ibudget) is not list:\n",
    "                bfr_data_used4MHWs_sel[~ibudget] = np.nan\n",
    "\n",
    "            if ireg['region_name'] is not 'Global':\n",
    "                # for regions to keep\n",
    "                if 'lon_min' in ireg.keys():\n",
    "                    bfr_data_used4MHWs_sel[XC_lon_reshaped < ireg[\"lon_min\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[XC_lon_reshaped > ireg[\"lon_max\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[YC_lat_reshaped < ireg[\"lat_min\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[YC_lat_reshaped > ireg[\"lat_max\"]] = np.nan\n",
    "                # for regions to exclude    \n",
    "                elif 'lon_min_exclude2' in ireg.keys():\n",
    "                    for ix in np.arange(0, len(ireg['lon_min_exclude2']), 1):\n",
    "                        bfr_data_used4MHWs_sel[np.logical_and(\n",
    "                            np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "                                           XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "                            np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "                                           YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))] = np.nan    \n",
    "\n",
    "            mhw_mask = np.ones(bfr_data_used4MHWs_sel.shape)\n",
    "            mhw_mask[np.isnan(bfr_data_used4MHWs_sel)] = 0\n",
    "\n",
    "            area_mhws = area_reshaped * mhw_mask\n",
    "            area_mhws_2d = area_mhws.reshape(bfr_data_used4MHWs_sel.shape[0], -1)\n",
    "            area_mhws_1d = np.sum(area_mhws_2d, axis=1)\n",
    "\n",
    "            scaling_factor = np.nanmax(area_mhws_1d/area_tot * 100)\n",
    "            scaling_factor_str = str('{0:.2f}'.format(scaling_factor))\n",
    "            plt.plot(time[eval(ind_time_start_slice):eval(ind_time_end_slice)+1],\n",
    "                     (area_mhws_1d/area_tot * 100) / scaling_factor, label=ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title('Percentage of area covered by MHWs where condition \"' + ibudget_names + ' - ' + condition_name + '\" is met', fontsize=16)\n",
    "        plt.xlabel('Time', fontsize=16)\n",
    "        plt.ylabel('%', fontsize=16)\n",
    "#         plt.savefig(f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/area_covered_global_{ibudget_names}_{condition_name}.png', dpi=1000)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a56fbc",
   "metadata": {},
   "source": [
    "### Plots for NO Global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca0e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one plot for each budget condition and for each onset/decline/MHWs condition - NO GLOBAL\n",
    "for ibudget, ibudget_names in zip(budget_condition_list_reshaped, budget_condition_list_names):\n",
    "    for condition, condition_name in zip(conditions_events_onset_decline, conditions_events_onset_decline_names):\n",
    "        plt.figure(figsize=(20,8))  # Create a new figure for each combination of budget condition and condition onset\n",
    "        for ireg in regions_condition_list:\n",
    "            bfr_data_used4MHWs_sel = copy.deepcopy(data_used4MHWs_sel)\n",
    "            bfr_data_used4MHWs_sel[~condition] = np.nan\n",
    "\n",
    "            if type(ibudget) is not list:\n",
    "                bfr_data_used4MHWs_sel[~ibudget] = np.nan\n",
    "\n",
    "            if ireg['region_name'] is not 'Global':\n",
    "                # for regions to keep\n",
    "                if 'lon_min' in ireg.keys():\n",
    "                    bfr_data_used4MHWs_sel[XC_lon_reshaped < ireg[\"lon_min\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[XC_lon_reshaped > ireg[\"lon_max\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[YC_lat_reshaped < ireg[\"lat_min\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[YC_lat_reshaped > ireg[\"lat_max\"]] = np.nan\n",
    "                # for regions to exclude    \n",
    "                elif 'lon_min_exclude2' in ireg.keys():\n",
    "                    for ix in np.arange(0, len(ireg['lon_min_exclude2']), 1):\n",
    "                        bfr_data_used4MHWs_sel[np.logical_and(\n",
    "                            np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "                                           XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "                            np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "                                           YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))] = np.nan    \n",
    "\n",
    "            mhw_mask = np.ones(bfr_data_used4MHWs_sel.shape)\n",
    "            mhw_mask[np.isnan(bfr_data_used4MHWs_sel)] = 0\n",
    "\n",
    "            area_mhws = area_reshaped * mhw_mask\n",
    "            area_mhws_2d = area_mhws.reshape(bfr_data_used4MHWs_sel.shape[0], -1)\n",
    "            area_mhws_1d = np.sum(area_mhws_2d, axis=1)\n",
    "\n",
    "            scaling_factor = np.nanmax(area_mhws_1d/area_tot * 100)\n",
    "            scaling_factor_str = str('{0:.2f}'.format(scaling_factor))\n",
    "            plt.plot(time[eval(ind_time_start_slice):eval(ind_time_end_slice)+1],\n",
    "                     (area_mhws_1d/area_tot * 100) / scaling_factor, label=ireg['region_name'] + ' (' + scaling_factor_str + ')', linewidth = 2)\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title('Percentage of area covered by MHWs where condition \"' + ibudget_names + ' - ' + condition_name + '\" is met', fontsize=16)\n",
    "        plt.xlabel('Time', fontsize=16)\n",
    "        plt.ylabel('%', fontsize=16)\n",
    "        plt.savefig(f'/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/code/line_plots/area_covered_MHWs/area_covered_{ibudget_names}_{condition_name}.png', dpi=1000)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68a7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfb23e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3ec81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b4c1caf",
   "metadata": {},
   "source": [
    "# DO NOT TOUCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b89f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one plot for each budget condition and for each onset/decline/MHWs condition\n",
    "for ibudget, ibudget_names in zip(budget_condition_list_reshaped, budget_condition_list_names):\n",
    "    for condition, condition_name in zip(conditions_events_onset_decline, conditions_events_onset_decline_names):\n",
    "        plt.figure(figsize=(15,6))  # Create a new figure for each combination of budget condition and condition onset\n",
    "        for ireg in regions_condition_list:\n",
    "            bfr_data_used4MHWs_sel = copy.deepcopy(data_used4MHWs_sel)\n",
    "            bfr_data_used4MHWs_sel[~condition] = np.nan\n",
    "\n",
    "            if type(ibudget) is not list:\n",
    "                bfr_data_used4MHWs_sel[~ibudget] = np.nan\n",
    "\n",
    "            if ireg['region_name'] is not 'Global':\n",
    "                # for regions to keep\n",
    "                if 'lon_min' in ireg.keys():\n",
    "                    bfr_data_used4MHWs_sel[XC_lon_reshaped < ireg[\"lon_min\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[XC_lon_reshaped > ireg[\"lon_max\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[YC_lat_reshaped < ireg[\"lat_min\"]] = np.nan\n",
    "                    bfr_data_used4MHWs_sel[YC_lat_reshaped > ireg[\"lat_max\"]] = np.nan\n",
    "                # for regions to exclude    \n",
    "                elif 'lon_min_exclude2' in ireg.keys():\n",
    "                    for ix in np.arange(0, len(ireg['lon_min_exclude2']), 1):\n",
    "                        bfr_data_used4MHWs_sel[np.logical_and(\n",
    "                            np.logical_and(XC_lon_reshaped >= ireg[\"lon_min_exclude2\"][ix],\n",
    "                                           XC_lon_reshaped <= ireg[\"lon_max_exclude2\"][ix]),\n",
    "                            np.logical_and(YC_lat_reshaped >= ireg[\"lat_min_exclude2\"][ix],\n",
    "                                           YC_lat_reshaped <= ireg[\"lat_max_exclude2\"][ix]))] = np.nan    \n",
    "\n",
    "            mhw_mask = np.ones(bfr_data_used4MHWs_sel.shape)\n",
    "            mhw_mask[np.isnan(bfr_data_used4MHWs_sel)] = 0\n",
    "\n",
    "            area_mhws = area_reshaped * mhw_mask\n",
    "            area_mhws_2d = area_mhws.reshape(bfr_data_used4MHWs_sel.shape[0], -1)\n",
    "            area_mhws_1d = np.sum(area_mhws_2d, axis=1)\n",
    "\n",
    "            scaling_factor = np.nanmax(area_mhws_1d/area_tot * 100)\n",
    "            scaling_factor_str = str('{0:.2f}'.format(scaling_factor))\n",
    "            plt.plot(time[eval(ind_time_start_slice):eval(ind_time_end_slice)+1],\n",
    "                     (area_mhws_1d/area_tot * 100) / scaling_factor, label=ireg['region_name'] + ' (' + scaling_factor_str + ')')\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title('Percentage of area covered by MHWs where condition \"' + ibudget_names + ' - ' + condition_name + '\" is met', fontsize=16)\n",
    "        plt.xlabel('Time', fontsize=16)\n",
    "        plt.ylabel('%', fontsize=16)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7b0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check regions excluded/kept\n",
    "\n",
    "# import cartopy.crs as ccrs\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import shapely.geometry as sgeom\n",
    "\n",
    "# # Define bounding box coordinates and labels\n",
    "# bounding_boxes = [\n",
    "#     ((20, 146, -60, 30), 'Indian (2keep)', 'blue', 'None'),  \n",
    "#     ((-80, 20, -90, 90), 'Atlantic (2keep)', 'green', 'None'),      \n",
    "#     ((-170.5, -140.5, -45.5, -25.5), 'SWP (2keep)', 'orange', 'None'),      \n",
    "#     ((-150.5, -134.5, 39.5, 50.5), 'NEP (2keep)', 'purple', 'None'), \n",
    "#     ((147, 155, -45, -37), 'TASMAN (2keep)', 'gold', 'None')     \n",
    "# ]\n",
    "\n",
    "# # Create a PlateCarree projection\n",
    "# projection = ccrs.PlateCarree()\n",
    "\n",
    "# # Create a figure and axis with Cartopy projection\n",
    "# fig, ax = plt.subplots(subplot_kw={'projection': projection}, figsize=(20,6))\n",
    "\n",
    "# # Set extent to global\n",
    "# ax.set_global()\n",
    "\n",
    "# # Add coastlines\n",
    "# ax.coastlines()\n",
    "\n",
    "# # Loop through bounding boxes and add them to the plot\n",
    "# for bbox, label, color, color_shading in bounding_boxes:\n",
    "#     lon_min, lon_max, lat_min, lat_max = bbox\n",
    "#     bounding_box = sgeom.box(lon_min, lat_min, lon_max, lat_max)\n",
    "#     ax.add_geometries([bounding_box], crs=projection, edgecolor=color, facecolor=color_shading, linewidth=2)\n",
    "    \n",
    "#     # Add label\n",
    "#     ax.text((lon_min + lon_max) / 2, (lat_min + lat_max) / 2, label, transform=projection,\n",
    "#             horizontalalignment='center', verticalalignment='center', fontsize=10, color=color)\n",
    "\n",
    "# # Add gridlines\n",
    "# ax.gridlines(draw_labels=True, linestyle='--')\n",
    "\n",
    "# # Add title\n",
    "# plt.title('Global Map with Multiple Bounding Boxes')\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# import cartopy.crs as ccrs\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import shapely.geometry as sgeom\n",
    "\n",
    "# # Define bounding box coordinates and labels\n",
    "# bounding_boxes = [    \n",
    "#     ((-180, -100, 20, 90), 'Pacific_noEQ', 'red', 'None'),      \n",
    "#     ((-180, -70, -20, -90), 'Pacific_noEQ', 'red', 'None'),      \n",
    "#     ((130, 180, -20, -90), 'Pacific_noEQ', 'red', 'None'),      \n",
    "#     ((130, 180, 20, 90), 'Pacific_noEQ', 'red', 'None')\n",
    "# ]\n",
    "\n",
    "# # Create a PlateCarree projection\n",
    "# projection = ccrs.PlateCarree()\n",
    "\n",
    "# # Create a figure and axis with Cartopy projection\n",
    "# fig, ax = plt.subplots(subplot_kw={'projection': projection}, figsize=(20,6))\n",
    "\n",
    "# # Set extent to global\n",
    "# ax.set_global()\n",
    "\n",
    "# # Add coastlines\n",
    "# ax.coastlines()\n",
    "\n",
    "# # Loop through bounding boxes and add them to the plot\n",
    "# for bbox, label, color, color_shading in bounding_boxes:\n",
    "#     lon_min, lon_max, lat_min, lat_max = bbox\n",
    "#     bounding_box = sgeom.box(lon_min, lat_min, lon_max, lat_max)\n",
    "#     ax.add_geometries([bounding_box], crs=projection, edgecolor=color, facecolor=color_shading, linewidth=2)\n",
    "    \n",
    "#     # Add label\n",
    "#     ax.text((lon_min + lon_max) / 2, (lat_min + lat_max) / 2, label, transform=projection,\n",
    "#             horizontalalignment='center', verticalalignment='center', fontsize=10, color=color)\n",
    "\n",
    "# # Add gridlines\n",
    "# ax.gridlines(draw_labels=True, linestyle='--')\n",
    "\n",
    "# # Add title\n",
    "# plt.title('Global Map with Multiple Bounding Boxes')\n",
    "\n",
    "# # Show plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17610d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f5e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b258bcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e2ef70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5029403c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ireg in area_mhws_store.keys():\n",
    "    plt.figure(figsize=(15,6))\n",
    "    bfr_area_msk = area_mhws_store[ireg].flatten()>0\n",
    "    bfr_XC = XC_lon_reshaped.flatten()[bfr_area_msk]\n",
    "    bfr_YC = YC_lat_reshaped.flatten()[bfr_area_msk]\n",
    "    plt.hist2d(bfr_XC, bfr_YC, bins=360)\n",
    "    plt.colorbar()\n",
    "#     plt.plot(XC_lon_reshaped.flatten(), YC_lat_reshaped.flatten(), area_mhws_store[ireg].flatten(), linestyle = '', marker = '.')\n",
    "    plt.title(ireg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9476bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e2029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eaba6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'peak_tstep'\n",
    "# 'start_tstep_msk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0405bebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed260a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06b44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have these arrays defined:\n",
    "# peak_tstep_2d: numpy array of shape (9495, 105300)\n",
    "# start_tstep_msk_2d: numpy array of shape (9495, 105300)\n",
    "# onset_mask: numpy array of shape (9495, 105300)\n",
    "\n",
    "# Create a boolean mask where start_tstep_msk_2d equals 1\n",
    "mask = start_tstep_msk_2d == 1\n",
    "\n",
    "# Reshape peak_tstep_2d to match the shape of onset_mask\n",
    "reshaped_peak = peak_tstep_2d[:, :, np.newaxis]\n",
    "\n",
    "# Create a range of indices from i_t to peak_tstep_2d[i_t, ix] inclusive\n",
    "indices = np.arange(onset_mask.shape[0])[:, np.newaxis, np.newaxis] <= reshaped_peak\n",
    "\n",
    "# Combine the mask and indices to set values in onset_mask\n",
    "onset_mask[mask & indices] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afbfc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be0281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolor(mhw_mask[0,:,:])\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lon1d = XC_lon_reshaped.flatten()\n",
    "# lat1d = YC_lat_reshaped.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85df252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.scatter(lon1d[mhw_mask.flatten()==1], lat1d[mhw_mask.flatten()==1], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load area file\n",
    "# area = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/metadata_ecco/ECCOv4r4_area_1993_2017.nc')\n",
    "# area_transpose = area.area.values #.transpose(0, 2, 1)\n",
    "# # Reshape to match data_used4MHWs\n",
    "# area_reshaped = area_transpose.reshape((data_used4MHWs.shape[1], data_used4MHWs.shape[2]))\n",
    "# area_reshaped = np.repeat(np.expand_dims(area_reshaped, axis=2), data_used4MHWs.shape[0], axis=2)\n",
    "# area_reshaped = area_reshaped.transpose(2, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daae307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19a74c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3157f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e519cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add OISST in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b6708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line plot area covered by MHWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdate = date(year_start,1,2)   # start date\n",
    "# edate = date(2017,12,31)   # end date\n",
    "# time = pandas.date_range(sdate,edate-timedelta(days=1),freq='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaafc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Percentage of area covered by MHWs in time\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(time_sel, area_mhws_1d/area_tot*100)\n",
    "plt.title('Percentage of area covered by MHWs in time', fontsize = 18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0879dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(area_mhws_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add plot percentage of area covered by MHWs where each term of the budget is dominant\n",
    "# load of heat budget terms\n",
    "# for each term, we look when one is bigger than the other 2\n",
    "# we create a new mask in addition to mhw_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bfe8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(area_mhws[0,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfb4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(mhw_mask[0,:,:])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a22c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(find_mhws_info_data['G_advection_eventAve'][0,:,:])\n",
    "plt.colorbar()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5b9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305b328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f0f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ca8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to make maps\n",
    "def plot_map_from_scattered_TEST(XC_lon, YC_lat, d2plot, keyplot, year_start, year_end):\n",
    "\n",
    "    #__________\n",
    "    # Set data needed for the map\n",
    "    #__________    \n",
    "    if dataset_tag == 'ECCOv4r4_heat':\n",
    "        # Reshape XC_lon and YC_lat to match data2plot shape\n",
    "        d2plot_lon = np.reshape(XC_lon.XC_lon.values, [XC_lon.XC_lon.shape[0], XC_lon.XC_lon.shape[1]*XC_lon.XC_lon.shape[2]])\n",
    "        d2plot_lat = np.reshape(YC_lat.YC_lat.values, [YC_lat.YC_lat.shape[0], YC_lat.YC_lat.shape[1]*YC_lat.YC_lat.shape[2]])\n",
    "\n",
    "        # Shift longitudes\n",
    "        #d2plot_lon_shifted = shift_longitude(d2plot_lon)\n",
    "\n",
    "        # Reshape XC_lon and YC_lat\n",
    "        points = np.concatenate((np.reshape(d2plot_lon, [d2plot_lon.shape[0]*d2plot_lon.shape[1], 1]), np.reshape(d2plot_lat, [d2plot_lat.shape[0]*d2plot_lat.shape[1], 1])), axis=1)\n",
    "        # Reshape data2plot\n",
    "        values = np.reshape(d2plot, [d2plot.shape[0]*d2plot.shape[1], 1])\n",
    "\n",
    "        # Define the new grid for the map (360x180)\n",
    "        grid_x, grid_y = np.meshgrid(np.linspace(-179.5, 179.5, 360),\n",
    "                                     np.linspace(-89.5, 89.5, 180), indexing='ij')\n",
    "    \n",
    "        # Interpolate using nearest neighbor\n",
    "        grid_z0 = np.transpose(griddata(points, values, (grid_x, grid_y), method='nearest'), [1,0,2])[:,:,0]\n",
    "\n",
    "    elif dataset_tag == 'oisst_v2':\n",
    "\n",
    "        #Shift longitudes\n",
    "        grid_x, grid_y = np.meshgrid(XC_lon + 20., YC_lat, indexing='ij')\n",
    "        grid_z0 = d2plot\n",
    "              \n",
    "    elif dataset_tag == 'argo_ohc15_50':\n",
    "        grid_x, grid_y = np.meshgrid(XC_lon,YC_lat, indexing='ij')\n",
    "        grid_z0 = d2plot\n",
    "\n",
    "    #__________\n",
    "    # Set color bar details based on specific type of plot and/or variable being plotted\n",
    "    #__________    \n",
    "    # Determine vmax as the maximum absolute value\n",
    "    lev_or_int == 'ohc_k0_k5'\n",
    "    vmax = 90 #60\n",
    "    vmin = 0\n",
    "    cmap = plt.get_cmap('Reds') \n",
    "    levels = np.linspace(vmin, vmax, 30)\n",
    "    levels_cbar = levels\n",
    "            \n",
    "            \n",
    "    # Set other tags needed for the title of the map\n",
    "    if 'onset' in keyplot:\n",
    "        titletag = 'onset'\n",
    "        value_tag = 'positive'\n",
    "    elif 'decline' in keyplot:\n",
    "        titletag = 'decline'\n",
    "        value_tag = 'negative'\n",
    "    else:\n",
    "        titletag = 'events'\n",
    "        \n",
    "    common_name = remove_text_after_second_underscore(keyplot)\n",
    "    \n",
    "    #__________\n",
    "    # Make plot\n",
    "    #__________  \n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.Robinson(central_longitude=-180))\n",
    "    norm = mcolors.BoundaryNorm(levels, cmap.N)\n",
    "    im = ax.pcolormesh(grid_x.T, grid_y.T, grid_z0, cmap=cmap, norm=norm, transform=ccrs.PlateCarree())       \n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgrey', zorder=1)\n",
    "    fig.colorbar(im, ax=ax, ticks=levels_cbar, boundaries=levels)\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83535644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_after_second_underscore(name):\n",
    "    parts = name.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        return '_'.join(parts[:2])\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c82e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931aed8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d907e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a5b220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052d8c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1f0464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
