{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d98581a",
   "metadata": {},
   "source": [
    "### ECCOv4r4 DAILY - select the pressure level to keep, or calculate the integral within 2 pressure levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedc8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "import sys\n",
    "## Import the ecco_v4_py library into Python\n",
    "## =========================================\n",
    "##    If ecco_v4_py is not installed in your local Python library, \n",
    "##    tell Python where to find it.  The example below adds\n",
    "##    ecco_v4_py to the user's path if it is stored in the folder\n",
    "##    ECCOv4-py under the user's home directory\n",
    "\n",
    "from os.path import join,expanduser,exists,split\n",
    "user_home_dir = expanduser('~')\n",
    "sys.path.append(join(user_home_dir,'ECCOv4-py'))\n",
    "import ecco_v4_py as ecco\n",
    "\n",
    "# Suppress warning messages for a cleaner presentation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fc395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECCOv4r4_DATA = xr.open_dataset('/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/nc_files_zlev_or_zint/ECCOv4r4_DATA_cut_zlev0_1992_2018.nc')\n",
    "\n",
    "ECCOv4r4_DATA = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/heatBudgetECCO_jupyter/heat_nc_MONTHLY_files_for_donata/ECCOv4r4_DATA_1992_2017.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae6bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24bd321e",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2973d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECCO_dir = '/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/data/'\n",
    "ECCO_dir = '/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/'\n",
    "save_dir = join(ECCO_dir)\n",
    "integral_dir = '/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f613ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start = 1992  # Define the start year\n",
    "# year_end = 2018  # Define the end year (NOT included, will stop the year before this one)\n",
    "year_end = 1994  # Define the end year (NOT included, will stop the year before this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa755cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between selection of a single level or integral\n",
    "do_integral_tag = True\n",
    "do_single_lev = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fcb0f7",
   "metadata": {},
   "source": [
    "### Select a single level and save a single file for every terms (for all the years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f7ccc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth level:  0\n",
      "Starting:  G_total_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  G_advection_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  G_diffusion_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  G_forcing_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  adv_hConv_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  adv_vConv_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  dif_hConv_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  dif_vConv_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  G_advection_conv_zon_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  G_advection_conv_mer_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  G_diffusion_conv_zon_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  G_diffusion_conv_mer_cut\n",
      "1992\n",
      "1993\n",
      "Starting:  DATA_cut\n",
      "1992\n",
      "1993\n"
     ]
    }
   ],
   "source": [
    "if do_single_lev:\n",
    "    z_flag = 'zlev'\n",
    "    \n",
    "    # Define the variables to be saved\n",
    "    varnames = ['G_total_cut', 'G_advection_cut', 'G_diffusion_cut', 'G_forcing_cut',\n",
    "                'adv_hConv_cut', 'adv_vConv_cut', 'dif_hConv_cut', 'dif_vConv_cut',\n",
    "                'G_advection_conv_zon_cut', 'G_advection_conv_mer_cut',\n",
    "                'G_diffusion_conv_zon_cut', 'G_diffusion_conv_mer_cut', \n",
    "                'DATA_cut']\n",
    "\n",
    "    # need to do G_total for k5 and k9\n",
    "    \n",
    "    # Choose the vertical levels of interest\n",
    "    z_levels = [0]#, 5, 9]  # 0, 5, 9, or any other desired levels\n",
    "    \n",
    "    # Loop through the vertical levels\n",
    "    for z_lev in z_levels:\n",
    "        print('Depth level: ', z_lev)\n",
    "        # Loop through the variables\n",
    "        for varname in varnames:\n",
    "            print('Starting: ', varname)\n",
    "            final_dataset = None  # Initialize final dataset for each variable\n",
    "\n",
    "            # Loop through the years from 2004 to 2018\n",
    "            for year in range(year_start, year_end):\n",
    "                print(year)\n",
    "                # Define the folder name for the current year\n",
    "                folder_year = str(year)\n",
    "\n",
    "                # Create the directory path for loading\n",
    "                load_path = os.path.join(integral_dir, 'single_heat_terms', folder_year + '/')\n",
    "                \n",
    "                # Define the file name for loading\n",
    "                load_file_name = f'ECCOv4r4_{varname}_{year}.nc'\n",
    "\n",
    "                # Load the NetCDF file from the specified directory\n",
    "                load_file_path = os.path.join(load_path, load_file_name)\n",
    "                dataset = xr.open_dataset(load_file_path).sel(k=z_lev)\n",
    "                \n",
    "                # Check if the variable name contains \"_conv\" (files up to 2003 included do...)\n",
    "                if any(var in list(dataset.variables.keys()) for var in ['G_advection_conv_cut', 'G_diffusion_conv_cut']):   \n",
    "                    # If so, remove the _conv from the name\n",
    "                    dataset = dataset.rename_vars({f'{varname[:-4]}_conv_cut': varname})\n",
    "                \n",
    "                # Ensure coordinates match the final dataset\n",
    "                if final_dataset is None:\n",
    "                    final_dataset = dataset\n",
    "                else:\n",
    "                    # Concatenate along the 'time' dimension\n",
    "                    final_dataset = xr.concat([final_dataset, dataset], dim='time')\n",
    "\n",
    "            # Save the final dataset for the current variable\n",
    "            final_dataset.to_netcdf(save_dir + '/nc_files_zlev_or_zint/' + f'ECCOv4r4_{varname}_{z_flag}{z_lev}_{year_start}_{year_end}.nc', format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453fda2",
   "metadata": {},
   "source": [
    "### Compute the integral for X levels and save a single file for every terms (for all the years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde9c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The deepest ocean bottom is set to 6145m below the surface, with the vertical grid spacing increasing \n",
    "# from 10m near the surface to 457m near the ocean bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ae6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7824f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23209bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  G_total_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  G_advection_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  G_diffusion_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  G_forcing_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  adv_hConv_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  adv_vConv_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  dif_hConv_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  dif_vConv_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  G_advection_conv_zon_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  G_advection_conv_mer_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  G_diffusion_conv_zon_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  G_diffusion_conv_mer_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n",
      "Processing  DATA_cut\n",
      "Year being processed:\n",
      "1992\n",
      "1993\n"
     ]
    }
   ],
   "source": [
    "if do_integral_tag:\n",
    "    z_flag = 'zint'\n",
    "    Z_depth = xr.open_dataset('/Users/jacoposala/Desktop/CU/3.RESEARCH/NASA_project/NEW_heatBudgetECCO/\\\n",
    "data/outputs/single_heat_terms/ECCOv4r4_Z_depth_1993_2017.nc').Z_depth\n",
    "\n",
    "    expected_order = ('time', 'tile', 'k', 'j', 'i')\n",
    "\n",
    "    varnames = ['G_total_cut', 'G_advection_cut', 'G_diffusion_cut', 'G_forcing_cut',\n",
    "                'adv_hConv_cut', 'adv_vConv_cut', 'dif_hConv_cut', 'dif_vConv_cut',\n",
    "                'G_advection_conv_zon_cut', 'G_advection_conv_mer_cut',\n",
    "                'G_diffusion_conv_zon_cut', 'G_diffusion_conv_mer_cut', \n",
    "                'DATA_cut']\n",
    "\n",
    "  \n",
    "    for varname in varnames:\n",
    "        print('Processing ', varname)\n",
    "        print('Year being processed:')\n",
    "        final_dataset = None  # Initialize final dataset for each variable\n",
    "\n",
    "        for year in range(year_start, year_end):\n",
    "            print(year)\n",
    "            folder_year = str(year)\n",
    "            load_path = os.path.join(integral_dir, 'single_heat_terms', folder_year)\n",
    "            load_file_name = f'ECCOv4r4_{varname}_{year}.nc'\n",
    "            load_file_path = os.path.join(load_path, load_file_name)\n",
    "            dataset = xr.open_dataset(load_file_path)\n",
    "            \n",
    "            # Check if the variable name contains \"_conv\" (files up to 2003 included do...)\n",
    "            if any(var in list(dataset.variables.keys()) for var in ['G_advection_conv_cut', 'G_diffusion_conv_cut']):   \n",
    "                # If so, remove the _conv from the name\n",
    "                dataset = dataset.rename_vars({f'{varname[:-4]}_conv_cut': varname})\n",
    "                    \n",
    "            # Fix the order of coordinates for G_forcing_cut, adv_vConv_cut, and dif_vConv_cut\n",
    "            if varname in ['G_forcing_cut', 'adv_vConv_cut', 'dif_vConv_cut']:\n",
    "                dataset = dataset.transpose('time', 'k', 'tile', 'j', 'i')\n",
    "            \n",
    "            if varname == 'DATA_cut':\n",
    "                # Conversion to Kelvin for DATA_cut\n",
    "                variable_cut = dataset[varname] + 273.15\n",
    "            else:\n",
    "                variable_cut = dataset[varname]\n",
    "                        \n",
    "            depth_index_top_integral = 0  # corresponds to 5m\n",
    "            depth_index_bottom_integral = 5  # corresponds to 55m\n",
    "\n",
    "            thickness = np.abs(np.diff(Z_depth))\n",
    "\n",
    "            selected_variable_cut = variable_cut[:, depth_index_top_integral:depth_index_bottom_integral, :, :, :]\n",
    "            selected_thickness = thickness[depth_index_top_integral:depth_index_bottom_integral - 1]\n",
    "            reshaped_thickness_diff = np.reshape(selected_thickness, (1, -1, 1, 1, 1))\n",
    "\n",
    "            variable_integral = (\n",
    "                (selected_variable_cut[:, :-1, :, :, :].values + selected_variable_cut[:, 1:, :, :, :].values)\n",
    "                * reshaped_thickness_diff\n",
    "            ).sum(axis=1) / 2\n",
    "\n",
    "            # Save the integral to a new NetCDF file\n",
    "            save_path = os.path.join(save_dir + '/nc_files_zlev_or_zint/')\n",
    "            save_file_name = f'integral_{varname}_{year}.nc'\n",
    "            save_file_path = os.path.join(save_path, save_file_name)\n",
    "            \n",
    "            # Modify variable name and add _ohc_k0k5\n",
    "            varname_modified = varname.replace('_cut', '') + f'_ohc_k{depth_index_top_integral}_k{depth_index_bottom_integral}'\n",
    "        \n",
    "            integral_dataset = xr.Dataset(\n",
    "                {\n",
    "                    varname_modified: ([\"time\", \"tile\", \"j\", \"i\"], variable_integral)\n",
    "                },\n",
    "                coords={\n",
    "                    \"time\": variable_cut.time.values,\n",
    "                    \"tile\": np.arange(13),  # Adjust the range according to the number of tiles\n",
    "                    \"j\": np.arange(90),  # Adjust the range according to the latitude dimensions\n",
    "                    \"i\": np.arange(90),  # Adjust the range according to the longitude dimensions\n",
    "                }\n",
    "            )\n",
    "            # Save files for single years\n",
    "            #integral_dataset.to_netcdf(save_file_path)\n",
    "\n",
    "            if final_dataset is None:\n",
    "                final_dataset = integral_dataset\n",
    "            else:\n",
    "                final_dataset = xr.concat([final_dataset, integral_dataset], dim='time')\n",
    "\n",
    "        # At the end of all years, save the concatenated file, too\n",
    "        if final_dataset is not None:\n",
    "            # Save the final dataset to a single NetCDF file\n",
    "            final_save_path = os.path.join(save_path, f'ECCOv4r4_{varname_modified}_{year_start}_{year_end}.nc')\n",
    "            \n",
    "            final_dataset.to_netcdf(final_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75836edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbe86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01846cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forcing = xr.open_dataset('/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/single_heat_terms/2006/ECCOv4r4_G_forcing_cut_2006.nc')\n",
    "# forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875f66e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = xr.open_dataset('/Volumes/MyPassportForMac/MAC_15/NASA_project/2023/NEW_heatBudgetECCO_daily/data/outputs/single_heat_terms/2004/ECCOv4r4_DATA_cut_2004.nc')\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b328864",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = xr.open_dataset('/Users/jacoposala/Downloads/ECCOv4r4_G_diffusion_cut_zlev0_1992_2018.nc')\n",
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1297b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94706db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if do_single_lev:\n",
    "#     z_flag = 'zlev'\n",
    "#     # Define the variables to be saved\n",
    "#     varnames = ['G_total_cut', 'G_advection_cut', 'G_diffusion_cut', 'G_forcing_cut',\n",
    "#                 'adv_hConv_cut', 'adv_vConv_cut', 'dif_hConv_cut', 'dif_vConv_cut',\n",
    "#                 'G_advection_conv_zon_cut', 'G_advection_conv_mer_cut',\n",
    "#                 'G_diffusion_conv_zon_cut', 'G_diffusion_conv_mer_cut', \n",
    "#                 'DATA_cut']\n",
    "    \n",
    "#     # Choose the vertical level of interest\n",
    "#     z_lev = 9 # 0,5,9\n",
    "\n",
    "#     # Loop through the variables\n",
    "#     for varname in varnames:\n",
    "#         print('Starting: ', varname)\n",
    "#         final_dataset = None  # Initialize final dataset for each variable\n",
    "\n",
    "#         # Loop through the years from 2004 to 2018\n",
    "#         for year in range(year_start, year_end):\n",
    "#             # Define the folder name for the current year\n",
    "#             folder_year = str(year)\n",
    "\n",
    "#             # Create the directory path for loading\n",
    "#             load_path = os.path.join(integral_dir, 'single_heat_terms', folder_year)\n",
    "\n",
    "#             # Define the file name for loading\n",
    "#             load_file_name = f'ECCOv4r4_{varname}_{year}.nc'\n",
    "\n",
    "#             # Load the NetCDF file from the specified directory\n",
    "#             load_file_path = os.path.join(load_path, load_file_name)\n",
    "#             dataset = xr.open_dataset(load_file_path).sel(k=z_lev)\n",
    "            \n",
    "            \n",
    "#             # Ensure coordinates match the final dataset\n",
    "#             if final_dataset is None:\n",
    "#                 final_dataset = dataset\n",
    "#             else:\n",
    "#                 # Concatenate along the 'time' dimension\n",
    "#                 final_dataset = xr.concat([final_dataset, dataset], dim='time')\n",
    "\n",
    "#         # Save the final dataset for the current variable\n",
    "#         final_dataset.to_netcdf(save_dir + '/nc_files_zlev_or_zint/' + f'ECCOv4r4_{varname}_{z_flag}{z_lev}_{year_start}_{year_end}.nc', format='NETCDF4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d14e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
